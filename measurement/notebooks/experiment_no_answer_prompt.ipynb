{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment:  Identify effectiveness of \"no answer\" prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "LLM prompt is told: 'If you don't know the answer, just say that you don't know.' to help prevent hallucinations when context does not provide an answer.  It would be helpful to understand how effective prompt is at preventing responses when no context answer.\n",
    "\n",
    "**Test Approach**\n",
    "A sample of questions will be selected from QA corpus where answer is not possible.  LLM will be asked question with most relevant possible context but with expectation that context does not provide actual answer.  Assessment will measure what % of responses accurately indicate the LLM doesn't know.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckhill/miniforge3/envs/deh_measure/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Common import\n",
    "from deh.assessment import QASetRetriever\n",
    "from deh.assessment import QASetType\n",
    "from deh import settings\n",
    "from deh.eval import generate_experiment_dataset\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples:int = 100\n",
    "experiment_folder:str = \"../../data/evaluation/no-context-prompt-experiment/\"\n",
    "qa_data_set_file:str = \"../../data/qas/squad_qas.tsv\"\n",
    "\n",
    "# Create experiment folder:\n",
    "if not os.path.exists(experiment_folder):\n",
    "    Path(experiment_folder).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample QA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 questions sampled from QA corpus (../../data/qas/squad_qas.tsv)\n"
     ]
    }
   ],
   "source": [
    "# Only get impossible to answer questions:\n",
    "qa_set = QASetRetriever.get_qasets(\n",
    "    file_path = qa_data_set_file,\n",
    "    sample_size= num_samples,\n",
    "    qa_type = QASetType.IMPOSSIBLE_ONLY\n",
    ")\n",
    "\n",
    "print(f\"{len(qa_set)} questions sampled from QA corpus ({qa_data_set_file})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Responses with default prompt (does not specify to say don't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 100 question/answer pairs.\n",
      "Processing 2 of 100 question/answer pairs.\n",
      "Processing 3 of 100 question/answer pairs.\n",
      "Processing 4 of 100 question/answer pairs.\n",
      "Processing 5 of 100 question/answer pairs.\n",
      "Processing 6 of 100 question/answer pairs.\n",
      "Processing 7 of 100 question/answer pairs.\n",
      "Processing 8 of 100 question/answer pairs.\n",
      "Processing 9 of 100 question/answer pairs.\n",
      "Processing 10 of 100 question/answer pairs.\n",
      "Processing 11 of 100 question/answer pairs.\n",
      "Processing 12 of 100 question/answer pairs.\n",
      "Processing 13 of 100 question/answer pairs.\n",
      "Processing 14 of 100 question/answer pairs.\n",
      "Processing 15 of 100 question/answer pairs.\n",
      "Processing 16 of 100 question/answer pairs.\n",
      "Processing 17 of 100 question/answer pairs.\n",
      "Processing 18 of 100 question/answer pairs.\n",
      "Processing 19 of 100 question/answer pairs.\n",
      "Processing 20 of 100 question/answer pairs.\n",
      "Processing 21 of 100 question/answer pairs.\n",
      "Processing 22 of 100 question/answer pairs.\n",
      "Processing 23 of 100 question/answer pairs.\n",
      "Processing 24 of 100 question/answer pairs.\n",
      "Processing 25 of 100 question/answer pairs.\n",
      "Processing 26 of 100 question/answer pairs.\n",
      "Processing 27 of 100 question/answer pairs.\n",
      "Processing 28 of 100 question/answer pairs.\n",
      "Processing 29 of 100 question/answer pairs.\n",
      "Processing 30 of 100 question/answer pairs.\n",
      "Processing 31 of 100 question/answer pairs.\n",
      "Processing 32 of 100 question/answer pairs.\n",
      "Processing 33 of 100 question/answer pairs.\n",
      "Processing 34 of 100 question/answer pairs.\n",
      "Processing 35 of 100 question/answer pairs.\n",
      "Processing 36 of 100 question/answer pairs.\n",
      "Processing 37 of 100 question/answer pairs.\n",
      "Processing 38 of 100 question/answer pairs.\n",
      "Processing 39 of 100 question/answer pairs.\n",
      "Processing 40 of 100 question/answer pairs.\n",
      "Processing 41 of 100 question/answer pairs.\n",
      "Processing 42 of 100 question/answer pairs.\n",
      "Processing 43 of 100 question/answer pairs.\n",
      "Processing 44 of 100 question/answer pairs.\n",
      "Processing 45 of 100 question/answer pairs.\n",
      "Processing 46 of 100 question/answer pairs.\n",
      "Processing 47 of 100 question/answer pairs.\n",
      "Processing 48 of 100 question/answer pairs.\n",
      "Processing 49 of 100 question/answer pairs.\n",
      "Processing 50 of 100 question/answer pairs.\n",
      "Processing 51 of 100 question/answer pairs.\n",
      "Processing 52 of 100 question/answer pairs.\n",
      "Processing 53 of 100 question/answer pairs.\n",
      "Processing 54 of 100 question/answer pairs.\n",
      "Processing 55 of 100 question/answer pairs.\n",
      "Processing 56 of 100 question/answer pairs.\n",
      "Processing 57 of 100 question/answer pairs.\n",
      "Processing 58 of 100 question/answer pairs.\n",
      "Processing 59 of 100 question/answer pairs.\n",
      "Processing 60 of 100 question/answer pairs.\n",
      "Processing 61 of 100 question/answer pairs.\n",
      "Processing 62 of 100 question/answer pairs.\n",
      "Processing 63 of 100 question/answer pairs.\n",
      "Processing 64 of 100 question/answer pairs.\n",
      "Processing 65 of 100 question/answer pairs.\n",
      "Processing 66 of 100 question/answer pairs.\n",
      "Processing 67 of 100 question/answer pairs.\n",
      "Processing 68 of 100 question/answer pairs.\n",
      "Processing 69 of 100 question/answer pairs.\n",
      "Processing 70 of 100 question/answer pairs.\n",
      "Processing 71 of 100 question/answer pairs.\n",
      "Processing 72 of 100 question/answer pairs.\n",
      "Processing 73 of 100 question/answer pairs.\n",
      "Processing 74 of 100 question/answer pairs.\n",
      "Processing 75 of 100 question/answer pairs.\n",
      "Processing 76 of 100 question/answer pairs.\n",
      "Processing 77 of 100 question/answer pairs.\n",
      "Processing 78 of 100 question/answer pairs.\n",
      "Processing 79 of 100 question/answer pairs.\n",
      "Processing 80 of 100 question/answer pairs.\n",
      "Processing 81 of 100 question/answer pairs.\n",
      "Processing 82 of 100 question/answer pairs.\n",
      "Processing 83 of 100 question/answer pairs.\n",
      "Processing 84 of 100 question/answer pairs.\n",
      "Processing 85 of 100 question/answer pairs.\n",
      "Processing 86 of 100 question/answer pairs.\n",
      "Processing 87 of 100 question/answer pairs.\n",
      "Processing 88 of 100 question/answer pairs.\n",
      "Processing 89 of 100 question/answer pairs.\n",
      "Processing 90 of 100 question/answer pairs.\n",
      "Processing 91 of 100 question/answer pairs.\n",
      "Processing 92 of 100 question/answer pairs.\n",
      "Processing 93 of 100 question/answer pairs.\n",
      "Processing 94 of 100 question/answer pairs.\n",
      "Processing 95 of 100 question/answer pairs.\n",
      "Processing 96 of 100 question/answer pairs.\n",
      "Processing 97 of 100 question/answer pairs.\n",
      "Processing 98 of 100 question/answer pairs.\n",
      "Processing 99 of 100 question/answer pairs.\n",
      "Processing 100 of 100 question/answer pairs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response.question</th>\n",
       "      <th>response.hyde</th>\n",
       "      <th>response.answer</th>\n",
       "      <th>response.context</th>\n",
       "      <th>response.evaluation.grade</th>\n",
       "      <th>response.evaluation.description</th>\n",
       "      <th>response.execution_time</th>\n",
       "      <th>system_settings.gpu_enabled</th>\n",
       "      <th>system_settings.llm_model</th>\n",
       "      <th>system_settings.llm_prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>system_settings.text_chunk_size</th>\n",
       "      <th>system_settings.text_chunk_overlap</th>\n",
       "      <th>system_settings.context_similarity_threshold</th>\n",
       "      <th>system_settings.context_docs_retrieved</th>\n",
       "      <th>system_settings.docs_loaded</th>\n",
       "      <th>reference.question</th>\n",
       "      <th>reference.ground_truth</th>\n",
       "      <th>reference.is_impossible</th>\n",
       "      <th>reference.ref_context_id</th>\n",
       "      <th>reference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>False</td>\n",
       "      <td>Pedro Menendez de Aviles did not call the St. ...</td>\n",
       "      <td>[{'id': None, 'metadata': {'source': '../data/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>True</td>\n",
       "      <td>llama3.1:8b-instruct-q3_K_L</td>\n",
       "      <td>rlm/rag-prompt-llama</td>\n",
       "      <td>...</td>\n",
       "      <td>1500</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   response.question  response.hyde  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...          False   \n",
       "\n",
       "                                     response.answer  \\\n",
       "0  Pedro Menendez de Aviles did not call the St. ...   \n",
       "\n",
       "                                    response.context  \\\n",
       "0  [{'id': None, 'metadata': {'source': '../data/...   \n",
       "\n",
       "  response.evaluation.grade response.evaluation.description  \\\n",
       "0                                                             \n",
       "\n",
       "  response.execution_time  system_settings.gpu_enabled  \\\n",
       "0                00:00:05                         True   \n",
       "\n",
       "     system_settings.llm_model system_settings.llm_prompt  ...  \\\n",
       "0  llama3.1:8b-instruct-q3_K_L       rlm/rag-prompt-llama  ...   \n",
       "\n",
       "  system_settings.text_chunk_size system_settings.text_chunk_overlap  \\\n",
       "0                            1500                                100   \n",
       "\n",
       "   system_settings.context_similarity_threshold  \\\n",
       "0                                           1.0   \n",
       "\n",
       "   system_settings.context_docs_retrieved  system_settings.docs_loaded  \\\n",
       "0                                       6                         1256   \n",
       "\n",
       "                                  reference.question  reference.ground_truth  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...                           \n",
       "\n",
       "  reference.is_impossible reference.ref_context_id  reference_id  \n",
       "0                    True                      287             1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert(response) -> pd.DataFrame:\n",
    "    \"\"\"Converts retrieved JSON response to Pandas DataFrame\"\"\"\n",
    "    return pd.json_normalize(\n",
    "        data=response\n",
    "    )\n",
    "\n",
    "def api_endpoint(**kwargs) -> str:\n",
    "    \"\"\"Endpoint for answer.\n",
    "    parameters:\n",
    "    - hyde (h) = False\n",
    "    - evaluation (e) = False\n",
    "    - lmm prompt selection (lp) = 1\n",
    "    \"\"\"\n",
    "    query_params = \"&\".join([f\"{key}={kwargs[key]}\" for key in kwargs])\n",
    "    return f\"http://{settings.API_ANSWER_ENDPOINT}/answer?{query_params}&h=False&e=False&lp=1\"\n",
    "\n",
    "# Collect response:\n",
    "exp_df = generate_experiment_dataset(qa_set, convert, api_endpoint)\n",
    "\n",
    "# Store dataframe:\n",
    "exp_df.to_pickle( f\"{experiment_folder}/prompt_1.pkl\" )\n",
    "exp_df[0:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Responses with default prompt (specify to say don't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 100 question/answer pairs.\n",
      "Processing 2 of 100 question/answer pairs.\n",
      "Processing 3 of 100 question/answer pairs.\n",
      "Processing 4 of 100 question/answer pairs.\n",
      "Processing 5 of 100 question/answer pairs.\n",
      "Processing 6 of 100 question/answer pairs.\n",
      "Processing 7 of 100 question/answer pairs.\n",
      "Processing 8 of 100 question/answer pairs.\n",
      "Processing 9 of 100 question/answer pairs.\n",
      "Processing 10 of 100 question/answer pairs.\n",
      "Processing 11 of 100 question/answer pairs.\n",
      "Processing 12 of 100 question/answer pairs.\n",
      "Processing 13 of 100 question/answer pairs.\n",
      "Processing 14 of 100 question/answer pairs.\n",
      "Processing 15 of 100 question/answer pairs.\n",
      "Processing 16 of 100 question/answer pairs.\n",
      "Processing 17 of 100 question/answer pairs.\n",
      "Processing 18 of 100 question/answer pairs.\n",
      "Processing 19 of 100 question/answer pairs.\n",
      "Processing 20 of 100 question/answer pairs.\n",
      "Processing 21 of 100 question/answer pairs.\n",
      "Processing 22 of 100 question/answer pairs.\n",
      "Processing 23 of 100 question/answer pairs.\n",
      "Processing 24 of 100 question/answer pairs.\n",
      "Processing 25 of 100 question/answer pairs.\n",
      "Processing 26 of 100 question/answer pairs.\n",
      "Processing 27 of 100 question/answer pairs.\n",
      "Processing 28 of 100 question/answer pairs.\n",
      "Processing 29 of 100 question/answer pairs.\n",
      "Processing 30 of 100 question/answer pairs.\n",
      "Processing 31 of 100 question/answer pairs.\n",
      "Processing 32 of 100 question/answer pairs.\n",
      "Processing 33 of 100 question/answer pairs.\n",
      "Processing 34 of 100 question/answer pairs.\n",
      "Processing 35 of 100 question/answer pairs.\n",
      "Processing 36 of 100 question/answer pairs.\n",
      "Processing 37 of 100 question/answer pairs.\n",
      "Processing 38 of 100 question/answer pairs.\n",
      "Processing 39 of 100 question/answer pairs.\n",
      "Processing 40 of 100 question/answer pairs.\n",
      "Processing 41 of 100 question/answer pairs.\n",
      "Processing 42 of 100 question/answer pairs.\n",
      "Processing 43 of 100 question/answer pairs.\n",
      "Processing 44 of 100 question/answer pairs.\n",
      "Processing 45 of 100 question/answer pairs.\n",
      "Processing 46 of 100 question/answer pairs.\n",
      "Processing 47 of 100 question/answer pairs.\n",
      "Processing 48 of 100 question/answer pairs.\n",
      "Processing 49 of 100 question/answer pairs.\n",
      "Processing 50 of 100 question/answer pairs.\n",
      "Processing 51 of 100 question/answer pairs.\n",
      "Processing 52 of 100 question/answer pairs.\n",
      "Processing 53 of 100 question/answer pairs.\n",
      "Processing 54 of 100 question/answer pairs.\n",
      "Processing 55 of 100 question/answer pairs.\n",
      "Processing 56 of 100 question/answer pairs.\n",
      "Processing 57 of 100 question/answer pairs.\n",
      "Processing 58 of 100 question/answer pairs.\n",
      "Processing 59 of 100 question/answer pairs.\n",
      "Processing 60 of 100 question/answer pairs.\n",
      "Processing 61 of 100 question/answer pairs.\n",
      "Processing 62 of 100 question/answer pairs.\n",
      "Processing 63 of 100 question/answer pairs.\n",
      "Processing 64 of 100 question/answer pairs.\n",
      "Processing 65 of 100 question/answer pairs.\n",
      "Processing 66 of 100 question/answer pairs.\n",
      "Processing 67 of 100 question/answer pairs.\n",
      "Processing 68 of 100 question/answer pairs.\n",
      "Processing 69 of 100 question/answer pairs.\n",
      "Processing 70 of 100 question/answer pairs.\n",
      "Processing 71 of 100 question/answer pairs.\n",
      "Processing 72 of 100 question/answer pairs.\n",
      "Processing 73 of 100 question/answer pairs.\n",
      "Processing 74 of 100 question/answer pairs.\n",
      "Processing 75 of 100 question/answer pairs.\n",
      "Processing 76 of 100 question/answer pairs.\n",
      "Processing 77 of 100 question/answer pairs.\n",
      "Processing 78 of 100 question/answer pairs.\n",
      "Processing 79 of 100 question/answer pairs.\n",
      "Processing 80 of 100 question/answer pairs.\n",
      "Processing 81 of 100 question/answer pairs.\n",
      "Processing 82 of 100 question/answer pairs.\n",
      "Processing 83 of 100 question/answer pairs.\n",
      "Processing 84 of 100 question/answer pairs.\n",
      "Processing 85 of 100 question/answer pairs.\n",
      "Processing 86 of 100 question/answer pairs.\n",
      "Processing 87 of 100 question/answer pairs.\n",
      "Processing 88 of 100 question/answer pairs.\n",
      "Processing 89 of 100 question/answer pairs.\n",
      "Processing 90 of 100 question/answer pairs.\n",
      "Processing 91 of 100 question/answer pairs.\n",
      "Processing 92 of 100 question/answer pairs.\n",
      "Processing 93 of 100 question/answer pairs.\n",
      "Processing 94 of 100 question/answer pairs.\n",
      "Processing 95 of 100 question/answer pairs.\n",
      "Processing 96 of 100 question/answer pairs.\n",
      "Processing 97 of 100 question/answer pairs.\n",
      "Processing 98 of 100 question/answer pairs.\n",
      "Processing 99 of 100 question/answer pairs.\n",
      "Processing 100 of 100 question/answer pairs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response.question</th>\n",
       "      <th>response.hyde</th>\n",
       "      <th>response.answer</th>\n",
       "      <th>response.context</th>\n",
       "      <th>response.evaluation.grade</th>\n",
       "      <th>response.evaluation.description</th>\n",
       "      <th>response.execution_time</th>\n",
       "      <th>system_settings.gpu_enabled</th>\n",
       "      <th>system_settings.llm_model</th>\n",
       "      <th>system_settings.llm_prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>system_settings.text_chunk_size</th>\n",
       "      <th>system_settings.text_chunk_overlap</th>\n",
       "      <th>system_settings.context_similarity_threshold</th>\n",
       "      <th>system_settings.context_docs_retrieved</th>\n",
       "      <th>system_settings.docs_loaded</th>\n",
       "      <th>reference.question</th>\n",
       "      <th>reference.ground_truth</th>\n",
       "      <th>reference.is_impossible</th>\n",
       "      <th>reference.ref_context_id</th>\n",
       "      <th>reference_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>False</td>\n",
       "      <td>Pedro Menendez de Aviles called the St. Johns ...</td>\n",
       "      <td>[{'id': None, 'metadata': {'source': '../data/...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>True</td>\n",
       "      <td>llama3.1:8b-instruct-q3_K_L</td>\n",
       "      <td>rlm/rag-prompt-llama</td>\n",
       "      <td>...</td>\n",
       "      <td>1500</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   response.question  response.hyde  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...          False   \n",
       "\n",
       "                                     response.answer  \\\n",
       "0  Pedro Menendez de Aviles called the St. Johns ...   \n",
       "\n",
       "                                    response.context  \\\n",
       "0  [{'id': None, 'metadata': {'source': '../data/...   \n",
       "\n",
       "  response.evaluation.grade response.evaluation.description  \\\n",
       "0                                                             \n",
       "\n",
       "  response.execution_time  system_settings.gpu_enabled  \\\n",
       "0                00:00:25                         True   \n",
       "\n",
       "     system_settings.llm_model system_settings.llm_prompt  ...  \\\n",
       "0  llama3.1:8b-instruct-q3_K_L       rlm/rag-prompt-llama  ...   \n",
       "\n",
       "  system_settings.text_chunk_size system_settings.text_chunk_overlap  \\\n",
       "0                            1500                                100   \n",
       "\n",
       "   system_settings.context_similarity_threshold  \\\n",
       "0                                           1.0   \n",
       "\n",
       "   system_settings.context_docs_retrieved  system_settings.docs_loaded  \\\n",
       "0                                       6                         1256   \n",
       "\n",
       "                                  reference.question  reference.ground_truth  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...                           \n",
       "\n",
       "  reference.is_impossible reference.ref_context_id  reference_id  \n",
       "0                    True                      287             1  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert(response) -> pd.DataFrame:\n",
    "    \"\"\"Converts retrieved JSON response to Pandas DataFrame\"\"\"\n",
    "    return pd.json_normalize(\n",
    "        data=response\n",
    "    )\n",
    "\n",
    "def api_endpoint(**kwargs) -> str:\n",
    "    \"\"\"Endpoint for answer.\n",
    "    parameters:\n",
    "    - hyde (h) = False\n",
    "    - evaluation (e) = False\n",
    "    - lmm prompt selection (lp) = 0\n",
    "    \"\"\"\n",
    "    query_params = \"&\".join([f\"{key}={kwargs[key]}\" for key in kwargs])\n",
    "    return f\"http://{settings.API_ANSWER_ENDPOINT}/answer?{query_params}&h=False&e=False&lp=0\"\n",
    "\n",
    "# Collect response:\n",
    "exp_df = generate_experiment_dataset(qa_set, convert, api_endpoint)\n",
    "\n",
    "# Store dataframe:\n",
    "exp_df.to_pickle( f\"{experiment_folder}/prompt_0.pkl\" )\n",
    "exp_df[0:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and merge Experiment Datasets for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment results:\n",
    "p_0_retr_df = pd.read_pickle(f\"{experiment_folder}/prompt_0.pkl\")[[\"response.question\", \"response.answer\", \"response.execution_time\"]]\n",
    "p_0_retr_df = p_0_retr_df.reset_index(drop=True)\n",
    "\n",
    "p_1_retr_df = pd.read_pickle(f\"{experiment_folder}/prompt_1.pkl\")[[\"response.question\", \"response.answer\", \"response.execution_time\"]]\n",
    "p_1_retr_df = p_1_retr_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response.question_p_0</th>\n",
       "      <th>response.answer_p_0</th>\n",
       "      <th>response.execution_time_p_0</th>\n",
       "      <th>response.question_p_1</th>\n",
       "      <th>response.answer_p_1</th>\n",
       "      <th>response.execution_time_p_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>Pedro Menendez de Aviles called the St. Johns ...</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>Pedro Menendez de Aviles did not call the St. ...</td>\n",
       "      <td>00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State educational and economic development whe...</td>\n",
       "      <td>Education is a crucial factor in economic deve...</td>\n",
       "      <td>00:00:18</td>\n",
       "      <td>State educational and economic development whe...</td>\n",
       "      <td>Education has been a crucial factor in economi...</td>\n",
       "      <td>00:00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               response.question_p_0  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...   \n",
       "1  State educational and economic development whe...   \n",
       "\n",
       "                                 response.answer_p_0  \\\n",
       "0  Pedro Menendez de Aviles called the St. Johns ...   \n",
       "1  Education is a crucial factor in economic deve...   \n",
       "\n",
       "  response.execution_time_p_0  \\\n",
       "0                    00:00:25   \n",
       "1                    00:00:18   \n",
       "\n",
       "                               response.question_p_1  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...   \n",
       "1  State educational and economic development whe...   \n",
       "\n",
       "                                 response.answer_p_1  \\\n",
       "0  Pedro Menendez de Aviles did not call the St. ...   \n",
       "1  Education has been a crucial factor in economi...   \n",
       "\n",
       "  response.execution_time_p_1  \n",
       "0                    00:00:05  \n",
       "1                    00:00:04  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate datasets together for comparison:\n",
    "combined_df = pd.merge( p_0_retr_df, p_1_retr_df, left_index=True, right_index=True, suffixes=[\"_p_0\", \"_p_1\"])\n",
    "combined_df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response.question_p_0</th>\n",
       "      <th>response.answer_p_0</th>\n",
       "      <th>response.execution_time_p_0</th>\n",
       "      <th>response.question_p_1</th>\n",
       "      <th>response.answer_p_1</th>\n",
       "      <th>response.execution_time_p_1</th>\n",
       "      <th>DNK_p_0</th>\n",
       "      <th>DNK_p_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>Pedro Menendez de Aviles called the St. Johns ...</td>\n",
       "      <td>00:00:25</td>\n",
       "      <td>Why did Pedro Menendez de Aviles called the St...</td>\n",
       "      <td>Pedro Menendez de Aviles did not call the St. ...</td>\n",
       "      <td>00:00:05</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State educational and economic development whe...</td>\n",
       "      <td>Education is a crucial factor in economic deve...</td>\n",
       "      <td>00:00:18</td>\n",
       "      <td>State educational and economic development whe...</td>\n",
       "      <td>Education has been a crucial factor in economi...</td>\n",
       "      <td>00:00:04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               response.question_p_0  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...   \n",
       "1  State educational and economic development whe...   \n",
       "\n",
       "                                 response.answer_p_0  \\\n",
       "0  Pedro Menendez de Aviles called the St. Johns ...   \n",
       "1  Education is a crucial factor in economic deve...   \n",
       "\n",
       "  response.execution_time_p_0  \\\n",
       "0                    00:00:25   \n",
       "1                    00:00:18   \n",
       "\n",
       "                               response.question_p_1  \\\n",
       "0  Why did Pedro Menendez de Aviles called the St...   \n",
       "1  State educational and economic development whe...   \n",
       "\n",
       "                                 response.answer_p_1  \\\n",
       "0  Pedro Menendez de Aviles did not call the St. ...   \n",
       "1  Education has been a crucial factor in economi...   \n",
       "\n",
       "  response.execution_time_p_1  DNK_p_0  DNK_p_1  \n",
       "0                    00:00:05     True    False  \n",
       "1                    00:00:04    False    False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indicate if answer contains don't know:\n",
    "combined_df[\"DNK_p_0\"] = combined_df['response.answer_p_0'].str.contains(\"don't know\")\n",
    "combined_df[\"DNK_p_1\"] = combined_df['response.answer_p_1'].str.contains(\"don't know\")\n",
    "\n",
    "combined_df[0:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hallucinations prevented comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent p_0:\n",
    "pcnt_p_0 = len( combined_df[ combined_df[\"DNK_p_0\"] == True ] ) / len (combined_df) * 100\n",
    "pcnt_p_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percent p_1:\n",
    "pcnt_p_1 = len( combined_df[ combined_df[\"DNK_p_1\"] == True ] ) / len (combined_df) * 100\n",
    "pcnt_p_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Telling the prompt to respond with \"I do not know\" if not available in context reduces hallucinations by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcnt_p_0 - pcnt_p_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any performance hit from prompt enhancment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.15"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[\"response_diff\"] = pd.to_timedelta(combined_df[\"response.execution_time_p_0\"]).dt.total_seconds() - pd.to_timedelta(combined_df[\"response.execution_time_p_1\"]).dt.total_seconds()\n",
    "combined_df[\"response_diff\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deh_measure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
