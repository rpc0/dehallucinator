{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load environmental variables:\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a LLM\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "llm = ChatVertexAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = DirectoryLoader(\n",
    "    path=\"../data\",\n",
    "    glob=\"**/*.txt\"\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = rag_chain.invoke(\"What is Colorado's capital?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create question | ground-truth comparison\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../data/qas.tsv\") as f:\n",
    "    evaluation = [ q.strip().split(\"\\t\") for q in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "for q, a in evaluation:\n",
    "    result = rag_chain.invoke(q)\n",
    "    experiments.append( { \"q\": q, \"a\": result, \"truth\": a })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'q': 'In what country is Normandy located?',\n",
       "  'a': '## Normandy is located in **France**. Information extracted from the provided context directly supports this statement.  \\n\\n',\n",
       "  'truth': 'France'},\n",
       " {'q': 'What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?',\n",
       "  'a': 'Computational complexity theory is the branch of theoretical computer science that deals with classifying computational problems according to their inherent difficulty and their relationship to each other. It seeks to determine the time and memory resources required to solve different kinds of problems. \\n',\n",
       "  'truth': 'Computational complexity theory'},\n",
       " {'q': 'What is Southern California often abbreviated as?',\n",
       "  'a': 'Southern California is often abbreviated as SoCal.  It encompasses the 10 southernmost counties in the state, including Los Angeles, San Diego, and Orange County.   ',\n",
       "  'truth': 'SoCal'},\n",
       " {'q': 'What company was formed by the merger of Sky Television and British Satellite Broadcasting?',\n",
       "  'a': \"The merger of Sky Television and British Satellite Broadcasting formed BSkyB in November 1990. BSkyB became the UK's largest digital subscription television company. In 2014, the holding company British Sky Broadcasting Group plc changed its name to Sky plc after acquiring Sky Italia and a majority stake in Sky Deutschland. \\n\",\n",
       "  'truth': 'BSkyB'},\n",
       " {'q': 'What kind of economy does Victoria have?',\n",
       "  'a': 'Victoria has a highly diversified economy with service sectors like financial, property services, health, education, wholesale, retail, hospitality, and manufacturing constituting the majority of employment. Despite being the second highest in GSP, Victoria ranks fourth in terms of GSP per capita due to limited mining activity.',\n",
       "  'truth': 'diversified'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AnswerRelevancy' object has no attribute 'init_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevalchain\u001b[39;00m \u001b[39mimport\u001b[39;00m RagasEvaluatorChain\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mragas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     faithfulness,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     answer_relevancy,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# context_precision,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     context_recall,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/git-projects/learning/capstone/dehallucinator/notebooks/langchain_experiment.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m answer_rel_chain \u001b[39m=\u001b[39m RagasEvaluatorChain(metric\u001b[39m=\u001b[39;49manswer_relevancy)\n",
      "File \u001b[0;32m~/miniforge3/envs/deh/lib/python3.9/site-packages/ragas/langchain/evalchain.py:29\u001b[0m, in \u001b[0;36mRagasEvaluatorChain.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: t\u001b[39m.\u001b[39mAny):\n\u001b[1;32m     28\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric\u001b[39m.\u001b[39;49minit_model()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AnswerRelevancy' object has no attribute 'init_model'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720756594.414591   91926 tcp_posix.cc:809] IOMGR endpoint shutdown\n",
      "I0000 00:00:1720756599.414654   91926 tcp_posix.cc:809] IOMGR endpoint shutdown\n"
     ]
    }
   ],
   "source": [
    "from ragas.langchain.evalchain import RagasEvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    # context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "answer_rel_chain = RagasEvaluatorChain(metric=answer_relevancy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
