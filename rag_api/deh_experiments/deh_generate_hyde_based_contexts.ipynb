{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Change chunking strategy\n",
    "\n",
    "- change chunking --> chunk per article\n",
    "- recreate SQAUD database\n",
    "\n",
    "2.) Generate Hyde-based contexts\n",
    "\n",
    "- all files in one directory: hyde_based_contexts\n",
    "- each file called hyde_based_contexts.csv\n",
    "- each file contains:\n",
    "\n",
    "   - qid\n",
    "   - question\n",
    "   - hyde_article\n",
    "   - hyde_based_context\n",
    "\n",
    "Currently, files contain the following information:\n",
    "\n",
    "    - filename : hyde_contexts_<n>\n",
    "    - question, hyde_context\n",
    " \n",
    " ==> change strategy for hyde_generated_contexts\n",
    "\n",
    " a) read in complete dataset (\"title\", \"context\", \"qid\", \"question\", \"is_impossible\", \"answer\")\n",
    " b) read in all hyde_passages that already exist\n",
    " c) take a sample of size HYDE_SAMPLE_SIZE from the complete dataset\n",
    " d) \n",
    " create new list: hyde_based_contexts (dict elements:qid, question, hyde_article, hyde_based_context)\n",
    "\n",
    " for each member of the sample:\n",
    "\n",
    "   - get question qid and add it\n",
    "   - add question to dataset\n",
    "   - if not hyde_article exists:\n",
    "      generate hyde_article\n",
    "   - get hyde_based_context\n",
    "   - add new dict element with: qid, question, hyde_article, hyde_based_context)\n",
    "\n",
    "persist new dataset to file hyde_based_contexts_<n>\n",
    "\n",
    "ALTERNATIVE:\n",
    "\n",
    "use chain from video course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "from csv import DictReader\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Ollama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Prompts\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Runnables\n",
    "from langchain.schema.runnable import RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports for squad_scoring and prompts\n",
    "from pathlib import Path\n",
    "\n",
    "utils_folder = Path(\"..\")\n",
    "sys.path.append(str(utils_folder))\n",
    "\n",
    "utils_folder = Path(\"../src/deh\")\n",
    "sys.path.append(str(utils_folder))\n",
    "\n",
    "import squad_scoring\n",
    "import prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders for storing data and the results\n",
    "DATA_ROOT = \"../../../deh_data_results/data\"         # Set to your own data folder\n",
    "RESULTS_ROOT = \"../../../deh_data_results/results\"   # Set to your own results folder\n",
    "HYDE_BASED_CONTEXTS_ROOT = F\"{DATA_ROOT}/hyde_based_contexts\"   # Set to your own hyde-based contexts folder\n",
    "\n",
    "# Vector Store Parameters\n",
    "ollama_embedding_model = \"avr/sfr-embedding-mistral\"\n",
    "embeddings = OllamaEmbeddings(model=ollama_embedding_model)\n",
    "persist_directory = f\"{DATA_ROOT}/chroma_deh_rag_db\"\n",
    "collection_name = \"deh_rag\"\n",
    "VECTORIZE_SQUAD_DATASET = False      # Set to True to vectorize the squad dataset. If False, \n",
    "                                    # then the documents and their embeddings should already\n",
    "                                    # exist in the vector store.\n",
    "CREATE_QUESTION_CONTEXTS = False     # Set to True to create question contexts from the vector store; \n",
    "                                    # if False, the question contexts are loaded from a csv file.\n",
    "CREATE_HYDE_CONTEXTS = True         # Set to True to create hyde contexts; if False,\n",
    "                                    # the hyde contexts are loaded from a csv file.                                    \n",
    "\n",
    "# LLM Parameters\n",
    "CHAT_MODEL_NAME = \"llama3.1\"\n",
    "MAX_TOKENS = 100\n",
    "TEMPERATURE = 0.5\n",
    "TOP_P = 0.95\n",
    "FREQUENCY_PENALTY = 0.0\n",
    "PRESENCE_PENALTY = 0.0\n",
    "\n",
    "CURRENT_QUERY_PROMPT_IDX = 0\n",
    "\n",
    "# Bootstrap Parameters\n",
    "SAMPLE_SIZE = 1000\n",
    "BOOTSTRAPS_N = 10000\n",
    "#TODO check if this code is ok for setting the seed\n",
    "# SEED = 42\n",
    "# set_seed = random.seed(SEED)\n",
    "\n",
    "# Experiment Parameters - define all the experiments to run\n",
    "experiments = [{\"name\": \"NO_RAG\", \"rag\": False, \"rag_model\": None, \"query_prompt_idx\": 0, \"conduct\": False},\n",
    "               {\"name\": \"BASIC_RAG\", \"rag\": True, \"rag_model\": \"basic\", \"query_prompt_idx\": 1, \"conduct\": False},\n",
    "               {\"name\": \"BASIC_RAG_DONT_LIE\", \"rag\": True, \"rag_model\": \"basic_dont_lie\", \"query_prompt_idx\": 2, \"conduct\": False},\n",
    "               {\"name\": \"BASIC_RAG_HYDE\", \"rag\": True, \"rag_model\": \"basic_hyde\", \"query_prompt_idx\": 2, \"conduct\": True},\n",
    "               {\"name\": \"BASIC_RAG_MILVUS\", \"rag\": True, \"rag_model\": \"basic_milvus\", \"conduct\": False},\n",
    "               {\"name\": \"BASIC_RAG_SEMANTIC_CHUNKING\", \"rag\": True, \"rag_model\": \"basic_semantic_chunking\", \"conduct\": False},\n",
    "               {\"name\": \"BASIC_RAG_SUPPRESS_ANSWERS\", \"rag\": True, \"rag_model\": \"basic_suppress_answers\", \"query_prompt_idx\": 2, \"conduct\": False},\n",
    "               {\"name\": \"FULL_RAG\", \"rag\": True, \"rag_model\": \"full\", \"conduct\": False}]\n",
    "\n",
    "PERSIST_ANSWER_SAMPLES = False   # Set to True to persist the llm answers for each sample, for each experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the prompts and a function to get the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompts = [\n",
    "    PromptTemplate(\n",
    "        template=prompts.rag_text_prompts[2],\n",
    "        input_variables = [\"question\"]\n",
    "    ),\n",
    "    # PromptTemplate(\n",
    "    #     template=prompts.rag_text_prompts[1],\n",
    "    #     input_variables = [\"context\", \"question\"]\n",
    "    # ),\n",
    "\n",
    "    PromptTemplate(\n",
    "        template = \"\"\"\n",
    "    You are an assistant for question-answering tasks.\n",
    "    Please only use the following pieces of retrieved context to answer the question.\n",
    "    Use ten words maximum and keep the answer concise.\n",
    "\n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\",\n",
    "        input_variables = [\"context\", \"question\"]\n",
    "    ),\n",
    "\n",
    "    PromptTemplate(\n",
    "        template=(\"\"\"\n",
    "                You are an assistant for question-answering tasks.\n",
    "                Use the following pieces of retrieved context to answer the question.\n",
    "                If you don't know the answer, just return 'DONT KNOW'. \n",
    "                If you know the answer, keep it as short and concise as possible,\n",
    "                i.e. to a maximum of a couple of words.\n",
    "\n",
    "                Question: {question}\n",
    "                Context: {context}\n",
    "\n",
    "                Answer:\n",
    "                \"\"\"\n",
    "        ),\n",
    "        input_variables=[\"context\", \"question\"]\n",
    "    ),\n",
    "    PromptTemplate(\n",
    "        template = prompts.hyde_prompts[1],\n",
    "        input_variables = [\"question\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the llm instance, based on the current query prompt\n",
    "def get_llm(current_query_prompt):\n",
    "    llm = ChatOllama(\n",
    "        prompt_template = current_query_prompt,\n",
    "        model = CHAT_MODEL_NAME,\n",
    "        max_tokens = MAX_TOKENS,\n",
    "        temperature = TEMPERATURE,\n",
    "        top_p = TOP_P,\n",
    "        frequency_penalty = FREQUENCY_PENALTY,\n",
    "        presence_penalty = PRESENCE_PENALTY,\n",
    "        gpu_use = True\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intialize the Vector Store (Chroma; Milvus to be added later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intiialize the Chroma vector store\n",
    "vector_store = Chroma(\n",
    "    #collection_name = collection_name,\n",
    "    collection_name = \"deh_rag_per_article\",\n",
    "    embedding_function = embeddings,\n",
    "    persist_directory = persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the SQuAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#articles in the dataset:     35\n",
      "#contexts in the dataset:   1204\n",
      "#questions in the dataset: 26232\n",
      "#unique questions in the dataset: 11849\n",
      "#unique qas in the dataset: 16209\n"
     ]
    }
   ],
   "source": [
    "data_file = f\"{DATA_ROOT}/dev-v2.0.json\"\n",
    "dataset = squad_scoring.load_dataset(data_file)\n",
    "\n",
    "articles = []\n",
    "contexts = []\n",
    "qas = []\n",
    "\n",
    "for article in dataset:\n",
    "    title = article[\"title\"]\n",
    "    articles.append(title)\n",
    "    for p in article['paragraphs']:\n",
    "        context = p[\"context\"]\n",
    "        contexts.append(context)\n",
    "        for qa in p['qas']:\n",
    "            question = qa[\"question\"]\n",
    "            id = qa[\"id\"]\n",
    "            is_impossible = qa[\"is_impossible\"]\n",
    "            if is_impossible:\n",
    "                for pa in qa[\"plausible_answers\"]:\n",
    "                    answer = pa[\"text\"]\n",
    "                    qas.append({\"title\": title, \"context\": context, \"qid\": id, \"question\": question, \n",
    "                                \"is_impossible\": is_impossible, \"answer\": answer})\n",
    "            else:\n",
    "                for a in qa[\"answers\"]:\n",
    "                    answer = a[\"text\"]\n",
    "                    qas.append({\"title\": title, \"context\": context, \"qid\": id, \"question\": question, \n",
    "                                \"is_impossible\": is_impossible, \"answer\": answer})\n",
    "                    \n",
    "# Store dataset as a csv file\n",
    "csv_file = f\"{DATA_ROOT}/dev-v2.0.csv\"\n",
    "with open(csv_file, mode='w') as file:\n",
    "    fieldnames = ['title', 'context', 'qid', 'question', 'is_impossible', 'answer']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for qa in qas:\n",
    "        writer.writerow(qa)                    \n",
    "\n",
    "unique_questions = list(set([qa[\"question\"] for qa in qas]))\n",
    "unique_qas = [dict(t) for t in {tuple(d.items()) for d in qas}]\n",
    "\n",
    "print(f\"#articles in the dataset:     {len(articles)}\")\n",
    "print(f\"#contexts in the dataset:   {len(contexts)}\")\n",
    "print(f\"#questions in the dataset: {len(qas)}\")   \n",
    "print(f\"#unique questions in the dataset: {len(unique_questions)}\")\n",
    "print(f\"#unique qas in the dataset: {len(unique_qas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If configured, chunk the SQuAD dataset and add the chunks to the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not vectorizing the squad dataset...\n"
     ]
    }
   ],
   "source": [
    "if VECTORIZE_SQUAD_DATASET:\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    article_contexts_lens = []\n",
    "    curr_id = 0\n",
    "\n",
    "    for article in dataset:\n",
    "        title = article[\"title\"]\n",
    "        article_contexts = []\n",
    "\n",
    "        for p in article['paragraphs']:\n",
    "            article_contexts.append(p[\"context\"])\n",
    "\n",
    "        all_article_contexts = \"\\n\\n\".join(article_contexts)\n",
    "        article_chunks = text_splitter.create_documents([all_article_contexts]) \n",
    "        for article_chunk in article_chunks:\n",
    "            article_chunk.metadata = {\"source\": \"squad\", \"article\": title}\n",
    "        ids = [str(i) for i in list(range(curr_id, curr_id + len(article_chunks)))]\n",
    "        curr_id += len(article_chunks)\n",
    "        vector_store.add_documents(documents=article_chunks, ids=ids)\n",
    "else:\n",
    "    print(\"Not vectorizing the squad dataset...\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyde-based Contexts\n",
    "\n",
    "Hyde:\n",
    "\n",
    "- if configured: generate Hyde-based contexts and then persist\n",
    "- else: read the Hyde-based contexts from a .csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = f\"{DATA_ROOT}/dev-v2.0.json\"\n",
    "dataset = squad_scoring.load_dataset(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_hyde_based_contexts(csv_file_path, hyde_baased_contexts):\n",
    "\n",
    "    # Write the the Hyde contexts to a CSV file\n",
    "    with open(csv_file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"qid\", \"question\", \"hyde_article\", \"hyde_based_context\"])\n",
    "        writer.writeheader()   # Write the header row\n",
    "        writer.writerows(hyde_baased_contexts)  # Write the data rows\n",
    "\n",
    "    print(f\"Data successfully written to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyde_based_contexts_path = f\"{HYDE_BASED_CONTEXTS_ROOT}/hyde_contexts_2_MASTER_COPY_UNBEDINGT_BEHALTEN.csv\"\n",
    "\n",
    "# hyde_based_contexts = []\n",
    "# with open(hyde_based_contexts_path, mode='r') as file:\n",
    "#     csv_reader = csv.reader(file)\n",
    "    \n",
    "#     for i, row in enumerate(csv_reader):\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "\n",
    "#         hyde_based_contexts.append({\"question\": row[0], \"hyde_context\": row[1]})\n",
    "        \n",
    "# #print(f\"#hyde_based_contexts before removing duplicates: {len(hyde_based_contexts)}\")\n",
    "# hyde_based_contexts_unique  = list({frozenset(item.items()): item for item in hyde_based_contexts}.values())\n",
    "# #print(f\"#hyde_based_contexts before removing duplicates: {len(hyde_based_contexts_unique)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_hyde_based_contexts = []\n",
    "\n",
    "# for i, hcb in enumerate(hyde_based_contexts_unique):\n",
    "\n",
    "#     if i %100 == 0:\n",
    "#         print(f\"Processing question {i}...\")\n",
    "\n",
    "#     question = hcb[\"question\"]\n",
    "    \n",
    "#     top_docs = vector_store.similarity_search(\n",
    "#         query = question,\n",
    "#         k = 5\n",
    "#     )\n",
    "#     hyde_based_context = \" \".join([top_doc.page_content for top_doc in top_docs])\n",
    "\n",
    "#     new_hyde_based_context = {}\n",
    "#     new_hyde_based_context[\"qid\"] = squad_scoring.get_qid_from_question(hcb[\"question\"], dataset)\n",
    "#     new_hyde_based_context[\"question\"] = question\n",
    "#     new_hyde_based_context[\"hyde_article\"] = hcb[\"hyde_context\"]\n",
    "#     new_hyde_based_context[\"hyde_based_context\"] = hyde_based_context\n",
    "#     new_hyde_based_contexts.append(new_hyde_based_context)\n",
    "\n",
    "# print(f\"#new_hyde_based_contexts: {len(new_hyde_based_contexts)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyde_based_contexts_persist_path = f\"{HYDE_BASED_CONTEXTS_ROOT}/hyde_based_contexts.csv\"\n",
    "# persist_hyde_based_contexts(hyde_based_contexts_persist_path, new_hyde_based_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyde_based_contexts_path = f\"{HYDE_BASED_CONTEXTS_ROOT}/hyde_based_contexts.csv\"\n",
    "\n",
    "hyde_based_contexts = []\n",
    "with open(hyde_based_contexts_path, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    for i, row in enumerate(csv_reader):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        hyde_based_contexts.append({\"qid\": row[0], \"question\": row[1], \n",
    "                                    \"hyde_article\": row[2], \"hyde_based_context\": row[3]})\n",
    "        \n",
    "qids_already_processed = [hbc[\"qid\"] for hbc in hyde_based_contexts]\n",
    "questions_already_processed = [hbc[\"question\"] for hbc in hyde_based_contexts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question 0...\n",
      "Question Upon what chemical characteristic is oxygen's solubility dependent? already processed. Skipping...\n",
      "Processing question 1...\n",
      "Processing question 2...\n",
      "Processing question 3...\n",
      "Processing question 4...\n",
      "Processing question 5...\n",
      "Processing question 6...\n",
      "Processing question 7...\n",
      "Processing question 8...\n",
      "Processing question 9...\n",
      "Processing question 10...\n",
      "Processing question 11...\n",
      "Processing question 12...\n",
      "Question What is an example of a problem to which effective algorithms have provided a solution in spite of the intractability associated with the breadth of sizes? already processed. Skipping...\n",
      "Processing question 13...\n",
      "Question What does it mean for a knot to be considered indecomposable? already processed. Skipping...\n",
      "Processing question 14...\n",
      "Processing question 15...\n",
      "Question How was this possible  already processed. Skipping...\n",
      "Processing question 16...\n",
      "Processing question 17...\n",
      "Question What is the largest suspension bridge in Germany? already processed. Skipping...\n",
      "Processing question 18...\n",
      "Processing question 19...\n",
      "Processing question 20...\n",
      "Question What do biostratigraphers want to understand about past climate? already processed. Skipping...\n",
      "Processing question 21...\n",
      "Processing question 22...\n",
      "Question In a steam turbine, what are discs mounted on? already processed. Skipping...\n",
      "Processing question 23...\n",
      "Processing question 24...\n",
      "Question What is the power-to-weight ratio of a steam plant compared to that of an internal combustion engine? already processed. Skipping...\n",
      "Processing question 25...\n",
      "Question How many Huguenots were there in France in 1685? already processed. Skipping...\n",
      "Processing question 26...\n",
      "Question Which company provides train service in Fresno? already processed. Skipping...\n",
      "Processing question 27...\n",
      "Processing question 28...\n",
      "Question When was a zoological garden established in the Praga Park? already processed. Skipping...\n",
      "Processing question 29...\n",
      "Processing question 30...\n",
      "Processing question 31...\n",
      "Processing question 32...\n",
      "Processing question 33...\n",
      "Question In what process is the uptake from oxygen necessary? already processed. Skipping...\n",
      "Processing question 34...\n",
      "Processing question 35...\n",
      "Question What impact does workers working harder have on productivity of a business? already processed. Skipping...\n",
      "Processing question 36...\n",
      "Processing question 37...\n",
      "Processing question 38...\n",
      "Processing question 39...\n",
      "Question What is the English translation of Het Scheur? already processed. Skipping...\n",
      "Processing question 40...\n",
      "Question Inspired by Shelley what was the name of Gandhi's doctrine? already processed. Skipping...\n",
      "Processing question 41...\n",
      "Processing question 42...\n",
      "Question What minor amount of liquid oxygen was produced by early French experimenters? already processed. Skipping...\n",
      "Processing question 43...\n",
      "Processing question 44...\n",
      "Processing question 45...\n",
      "Question Who led New France reinforcements in 1765? already processed. Skipping...\n",
      "Processing question 46...\n",
      "Processing question 47...\n",
      "Processing question 48...\n",
      "Processing question 49...\n",
      "Data successfully written to ../../../deh_data_results/data/hyde_based_contexts/hyde_based_contexts.csv\n"
     ]
    }
   ],
   "source": [
    "# Names of datasets : unique_questions, unique_qas\n",
    "# Generate HYDE_SAMPLE_SIZE random samples from the unique_qas and \n",
    "# generate the hyde_based_contexts for each of the samples\n",
    "HYDE_SAMPLE_SIZE = 50\n",
    "sample = random.sample(unique_qas, HYDE_SAMPLE_SIZE)\n",
    "\n",
    "current_query_prompt = query_prompts[3]\n",
    "llm = get_llm(current_query_prompt)\n",
    "runnable_chain = RunnableSequence(current_query_prompt | llm)\n",
    "\n",
    "for i, qa in enumerate(sample):\n",
    "    #if i %10 == 0:\n",
    "    print(f\"Processing question {i}...\")\n",
    "\n",
    "    question = qa[\"question\"]\n",
    "    if question in questions_already_processed:\n",
    "        print(f\"Question {question} already processed. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    new_hyde_based_context = {}\n",
    "    question = qa[\"question\"]\n",
    "    qid = qa[\"qid\"]\n",
    "\n",
    "    # generate Hyde article\n",
    "    response = runnable_chain.invoke({\"question\": question})\n",
    "    hyde_based_article = response.content\n",
    "\n",
    "    # generate Hyde context based on the Hyde article\n",
    "    top_docs = vector_store.similarity_search(\n",
    "        query = question,\n",
    "        k = 5\n",
    "    )\n",
    "    hyde_based_context = \" \".join([top_doc.page_content for top_doc in top_docs])\n",
    "\n",
    "    new_hyde_based_context[\"qid\"] = qid # squad_scoring.get_qid_from_question(hcb[\"question\"], dataset)\n",
    "    new_hyde_based_context[\"question\"] = question\n",
    "    new_hyde_based_context[\"hyde_article\"] = hyde_based_article\n",
    "    new_hyde_based_context[\"hyde_based_context\"] = hyde_based_context\n",
    "    \n",
    "    hyde_based_contexts.append(new_hyde_based_context)\n",
    "\n",
    "hyde_based_contexts_persist_path = f\"{HYDE_BASED_CONTEXTS_ROOT}/hyde_based_contexts.csv\"\n",
    "persist_hyde_based_contexts(hyde_based_contexts_persist_path, hyde_based_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyde_contexts_already_done(csv_file_path, suffixes_l):\n",
    "    # if not os.path.exists(csv_file_path):\n",
    "    #     return []\n",
    "\n",
    "    hyde_contexts_already_done = []\n",
    "    for suffix in suffixes_l:\n",
    "        csv_file_path_iter = csv_file_path[:-4] + suffix + \".csv\"\n",
    "        print(f\"Reading hyde contexts from a csv file: {csv_file_path_iter}\")\n",
    "\n",
    "        with open(csv_file_path_iter, mode='r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            \n",
    "            for i, row in enumerate(csv_reader):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                hyde_contexts_already_done.append({\"question\": row[0], \"hyde_context\": row[1]})\n",
    "    print(f\"len(hyde_contexts_already_done) --> {len(hyde_contexts_already_done)}\")\n",
    "    return hyde_contexts_already_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = f\"{DATA_ROOT}/hyde_contexts.csv\"\n",
    "\n",
    "hyde_contexts_already_done = get_hyde_contexts_already_done(csv_file_path, ['_1', '_2'])\n",
    "hyde_questions_already_done = [hc[\"question\"] for hc in hyde_contexts_already_done]\n",
    "print(hyde_questions_already_done[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE_HYDE_CONTEXTS = False\n",
    "# print(DATA_ROOT)\n",
    "# if CREATE_HYDE_CONTEXTS:\n",
    "#     print(f\"Creating Hyde contexts for the dataset and persisting these in a csv file...\")\n",
    "#     unique_questions = list(set([qa[\"question\"] for qa in qas]))\n",
    "#     print(f\"Number of unique questions: {len(unique_questions)}\")\n",
    "\n",
    "#     current_query_prompt = query_prompts[3]\n",
    "#     llm = get_llm(current_query_prompt)\n",
    "#     runnable_chain = RunnableSequence(current_query_prompt | llm)\n",
    "\n",
    "#     for i, question in enumerate(unique_questions[:3000]):\n",
    "#         #if i %10 == 0:\n",
    "#         print(\"---------------------------------------------------------------\")\n",
    "#         print(f\"Processing question {i}...\")\n",
    "#         print(f\"Question: {question}\")\n",
    "#         if question in hyde_questions_already_done:\n",
    "#             print(\"Question already done...\")\n",
    "#             continue\n",
    "#         response = runnable_chain.invoke({\"question\": question})\n",
    "#         hyde_contexts_already_done.append({\"question\": question, \"hyde_context\": response.content})\n",
    "#         hyde_questions_already_done.append(question)\n",
    "#         print(\"\")\n",
    "    \n",
    "#     csv_file_path = f\"{DATA_ROOT}/hyde_contexts_2.csv\"\n",
    "#     persist_hyde_contexts(csv_file_path, hyde_contexts_already_done)\n",
    "#     hyde_contexts = hyde_contexts_already_done\n",
    "\n",
    "# else:\n",
    "#     print(f\"Reading the Hyde contexts from a csv file...\")\n",
    "\n",
    "#     hyde_contexts = []\n",
    "#     #with open(csv_file_path, mode='r') as file:\n",
    "#     with open(f\"{DATA_ROOT}/hyde_contexts_2_MASTER_COPY_UNBEDINGT_BEHALTEN.csv\", mode='r') as file:\n",
    "#         csv_reader = csv.reader(file)\n",
    "        \n",
    "#         for i, row in enumerate(csv_reader):\n",
    "#             if i == 0:\n",
    "#                 continue\n",
    "#             hyde_contexts.append({\"question\": row[0], \"hyde_context\": row[1]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyde_s = set([hyde_context[\"question\"] for hyde_context in hyde_contexts])\n",
    "# len(hyde_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
