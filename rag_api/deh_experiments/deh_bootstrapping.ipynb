{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from langchain.schema.runnable import RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports for deh experiments specific modules\n",
    "from pathlib import Path\n",
    "\n",
    "utils_folder = Path(\"..\")\n",
    "sys.path.append(str(utils_folder))\n",
    "\n",
    "utils_folder = Path(\"../src/deh\")\n",
    "sys.path.append(str(utils_folder))\n",
    "\n",
    "utils_folder = Path(\".\")\n",
    "sys.path.append(str(utils_folder))\n",
    "\n",
    "import squad_scoring\n",
    "import deh_prompts\n",
    "import deh_vector_store\n",
    "globals().update(deh_vector_store.__dict__)\n",
    "import deh_squad_data\n",
    "import deh_hyde\n",
    "import deh_experiments_config\n",
    "globals().update(deh_experiments_config.__dict__)\n",
    "import deh_globals\n",
    "globals().update(deh_globals.__dict__)\n",
    "import deh_llm\n",
    "globals().update(deh_llm.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading SQuAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squad data...\n",
      "\n",
      "Loaded squad data from ../../../deh_data_results/data/squad_raw.csv\n",
      "Number of raw entries in squad_raw: 26232\n",
      "Number of unique titles: 35\n",
      "Number of unique contexts: 1204\n",
      "Number of unique questions: 11858\n",
      "Number of unique answers: 16209\n"
     ]
    }
   ],
   "source": [
    "# csv_file_path = f\"{DATA_ROOT}/qas_with_contexts_hello.csv\"\n",
    "\n",
    "print(f\"Loading squad data...\\n\")\n",
    "\n",
    "column_names = [\"title\", \"squad_context\", \"qid\", \"question\", \"is_impossible\", \"answer\"]\n",
    "\n",
    "try:\n",
    "    squad_raw = pd.read_csv(f\"{DATA_ROOT}/squad_raw.csv\", names=column_names, skiprows=1)\n",
    "    print(f\"Loaded squad data from {DATA_ROOT}/squad_raw.csv\")\n",
    "except:\n",
    "    print(f\"Failed to load squad data from {DATA_ROOT}/squad_raw.csv\")\n",
    "\n",
    "df_squad_raw = pd.DataFrame(squad_raw)\n",
    "print(f\"Number of raw entries in squad_raw: {len(df_squad_raw)}\")\n",
    "\n",
    "df_titles = pd.DataFrame(df_squad_raw['title'].unique(), columns=[\"title\"])\n",
    "print(f\"Number of unique titles: {len(df_titles)}\")\n",
    "\n",
    "df_contexts = pd.DataFrame(df_squad_raw['squad_context'].unique(), columns=[\"squad_context\"])\n",
    "print(f\"Number of unique contexts: {len(df_contexts)}\")\n",
    "\n",
    "df_qas = df_squad_raw[['title', 'squad_context', 'qid', 'question', 'is_impossible']].drop_duplicates()\n",
    "df_qas = df_qas.reset_index(drop=True)\n",
    "print(f\"Number of unique questions: {len(df_qas)}\")\n",
    "\n",
    "df_squad_answers = df_squad_raw[['qid', 'question', 'answer']].drop_duplicates()\n",
    "print(f\"Number of unique answers: {len(df_squad_answers)}\")           \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intialize the Vector Store (Chroma; Milvus not yet included); if configured, re-chunk the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating contexts for the dataset...\n",
      "Chunking method: naive\n",
      "Number of chunks --> 2743\n",
      "\n",
      "Adding chunk 0 to the vector store...\n",
      "Adding chunk 10 to the vector store...\n",
      "Adding chunk 20 to the vector store...\n",
      "Adding chunk 30 to the vector store...\n",
      "Adding chunk 40 to the vector store...\n",
      "Adding chunk 50 to the vector store...\n",
      "Adding chunk 60 to the vector store...\n",
      "Adding chunk 70 to the vector store...\n",
      "Adding chunk 80 to the vector store...\n",
      "Adding chunk 90 to the vector store...\n",
      "Adding chunk 100 to the vector store...\n",
      "Adding chunk 110 to the vector store...\n",
      "Adding chunk 120 to the vector store...\n",
      "Adding chunk 130 to the vector store...\n",
      "Adding chunk 140 to the vector store...\n",
      "Adding chunk 150 to the vector store...\n",
      "Adding chunk 160 to the vector store...\n",
      "Adding chunk 170 to the vector store...\n",
      "Adding chunk 180 to the vector store...\n",
      "Adding chunk 190 to the vector store...\n",
      "Adding chunk 200 to the vector store...\n",
      "Adding chunk 210 to the vector store...\n",
      "Adding chunk 220 to the vector store...\n",
      "Adding chunk 230 to the vector store...\n",
      "Adding chunk 240 to the vector store...\n",
      "Adding chunk 250 to the vector store...\n",
      "Adding chunk 260 to the vector store...\n",
      "Adding chunk 270 to the vector store...\n",
      "Adding chunk 280 to the vector store...\n",
      "Adding chunk 290 to the vector store...\n",
      "Adding chunk 300 to the vector store...\n",
      "Adding chunk 310 to the vector store...\n",
      "Adding chunk 320 to the vector store...\n",
      "Adding chunk 330 to the vector store...\n",
      "Adding chunk 340 to the vector store...\n",
      "Adding chunk 350 to the vector store...\n",
      "Adding chunk 360 to the vector store...\n",
      "Adding chunk 370 to the vector store...\n",
      "Adding chunk 380 to the vector store...\n",
      "Adding chunk 390 to the vector store...\n",
      "Adding chunk 400 to the vector store...\n",
      "Adding chunk 410 to the vector store...\n",
      "Adding chunk 420 to the vector store...\n",
      "Adding chunk 430 to the vector store...\n",
      "Adding chunk 440 to the vector store...\n",
      "Adding chunk 450 to the vector store...\n",
      "Adding chunk 460 to the vector store...\n",
      "Adding chunk 470 to the vector store...\n",
      "Adding chunk 480 to the vector store...\n",
      "Adding chunk 490 to the vector store...\n",
      "Adding chunk 500 to the vector store...\n",
      "Adding chunk 510 to the vector store...\n",
      "Adding chunk 520 to the vector store...\n",
      "Adding chunk 530 to the vector store...\n",
      "Adding chunk 540 to the vector store...\n",
      "Adding chunk 550 to the vector store...\n",
      "Adding chunk 560 to the vector store...\n",
      "Adding chunk 570 to the vector store...\n",
      "Adding chunk 580 to the vector store...\n",
      "Adding chunk 590 to the vector store...\n",
      "Adding chunk 600 to the vector store...\n",
      "Adding chunk 610 to the vector store...\n",
      "Adding chunk 620 to the vector store...\n",
      "Adding chunk 630 to the vector store...\n",
      "Adding chunk 640 to the vector store...\n",
      "Adding chunk 650 to the vector store...\n",
      "Adding chunk 660 to the vector store...\n",
      "Adding chunk 670 to the vector store...\n",
      "Adding chunk 680 to the vector store...\n",
      "Adding chunk 690 to the vector store...\n",
      "Adding chunk 700 to the vector store...\n",
      "Adding chunk 710 to the vector store...\n",
      "Adding chunk 720 to the vector store...\n",
      "Adding chunk 730 to the vector store...\n",
      "Adding chunk 740 to the vector store...\n",
      "Adding chunk 750 to the vector store...\n",
      "Adding chunk 760 to the vector store...\n",
      "Adding chunk 770 to the vector store...\n",
      "Adding chunk 780 to the vector store...\n",
      "Adding chunk 790 to the vector store...\n",
      "Adding chunk 800 to the vector store...\n",
      "Adding chunk 810 to the vector store...\n",
      "Adding chunk 820 to the vector store...\n",
      "Adding chunk 830 to the vector store...\n",
      "Adding chunk 840 to the vector store...\n",
      "Adding chunk 850 to the vector store...\n",
      "Adding chunk 860 to the vector store...\n",
      "Adding chunk 870 to the vector store...\n",
      "Adding chunk 880 to the vector store...\n",
      "Adding chunk 890 to the vector store...\n",
      "Adding chunk 900 to the vector store...\n",
      "Adding chunk 910 to the vector store...\n",
      "Adding chunk 920 to the vector store...\n",
      "Adding chunk 930 to the vector store...\n",
      "Adding chunk 940 to the vector store...\n",
      "Adding chunk 950 to the vector store...\n",
      "Adding chunk 960 to the vector store...\n",
      "Adding chunk 970 to the vector store...\n",
      "Adding chunk 980 to the vector store...\n",
      "Adding chunk 990 to the vector store...\n",
      "Adding chunk 1000 to the vector store...\n",
      "Adding chunk 1010 to the vector store...\n",
      "Adding chunk 1020 to the vector store...\n",
      "Adding chunk 1030 to the vector store...\n",
      "Adding chunk 1040 to the vector store...\n",
      "Adding chunk 1050 to the vector store...\n",
      "Adding chunk 1060 to the vector store...\n",
      "Adding chunk 1070 to the vector store...\n",
      "Adding chunk 1080 to the vector store...\n",
      "Adding chunk 1090 to the vector store...\n",
      "Adding chunk 1100 to the vector store...\n",
      "Adding chunk 1110 to the vector store...\n",
      "Adding chunk 1120 to the vector store...\n",
      "Adding chunk 1130 to the vector store...\n",
      "Adding chunk 1140 to the vector store...\n",
      "Adding chunk 1150 to the vector store...\n",
      "Adding chunk 1160 to the vector store...\n",
      "Adding chunk 1170 to the vector store...\n",
      "Adding chunk 1180 to the vector store...\n",
      "Adding chunk 1190 to the vector store...\n",
      "Adding chunk 1200 to the vector store...\n",
      "Adding chunk 1210 to the vector store...\n",
      "Adding chunk 1220 to the vector store...\n",
      "Adding chunk 1230 to the vector store...\n",
      "Adding chunk 1240 to the vector store...\n",
      "Adding chunk 1250 to the vector store...\n",
      "Adding chunk 1260 to the vector store...\n",
      "Adding chunk 1270 to the vector store...\n",
      "Adding chunk 1280 to the vector store...\n",
      "Adding chunk 1290 to the vector store...\n",
      "Adding chunk 1300 to the vector store...\n",
      "Adding chunk 1310 to the vector store...\n",
      "Adding chunk 1320 to the vector store...\n",
      "Adding chunk 1330 to the vector store...\n",
      "Adding chunk 1340 to the vector store...\n",
      "Adding chunk 1350 to the vector store...\n",
      "Adding chunk 1360 to the vector store...\n",
      "Adding chunk 1370 to the vector store...\n",
      "Adding chunk 1380 to the vector store...\n",
      "Adding chunk 1390 to the vector store...\n",
      "Adding chunk 1400 to the vector store...\n",
      "Adding chunk 1410 to the vector store...\n",
      "Adding chunk 1420 to the vector store...\n",
      "Adding chunk 1430 to the vector store...\n",
      "Adding chunk 1440 to the vector store...\n",
      "Adding chunk 1450 to the vector store...\n",
      "Adding chunk 1460 to the vector store...\n",
      "Adding chunk 1470 to the vector store...\n",
      "Adding chunk 1480 to the vector store...\n",
      "Adding chunk 1490 to the vector store...\n",
      "Adding chunk 1500 to the vector store...\n",
      "Adding chunk 1510 to the vector store...\n",
      "Adding chunk 1520 to the vector store...\n",
      "Adding chunk 1530 to the vector store...\n",
      "Adding chunk 1540 to the vector store...\n",
      "Adding chunk 1550 to the vector store...\n",
      "Adding chunk 1560 to the vector store...\n",
      "Adding chunk 1570 to the vector store...\n",
      "Adding chunk 1580 to the vector store...\n",
      "Adding chunk 1590 to the vector store...\n",
      "Adding chunk 1600 to the vector store...\n",
      "Adding chunk 1610 to the vector store...\n",
      "Adding chunk 1620 to the vector store...\n",
      "Adding chunk 1630 to the vector store...\n",
      "Adding chunk 1640 to the vector store...\n",
      "Adding chunk 1650 to the vector store...\n",
      "Adding chunk 1660 to the vector store...\n",
      "Adding chunk 1670 to the vector store...\n",
      "Adding chunk 1680 to the vector store...\n",
      "Adding chunk 1690 to the vector store...\n",
      "Adding chunk 1700 to the vector store...\n",
      "Adding chunk 1710 to the vector store...\n",
      "Adding chunk 1720 to the vector store...\n",
      "Adding chunk 1730 to the vector store...\n",
      "Adding chunk 1740 to the vector store...\n",
      "Adding chunk 1750 to the vector store...\n",
      "Adding chunk 1760 to the vector store...\n",
      "Adding chunk 1770 to the vector store...\n",
      "Adding chunk 1780 to the vector store...\n",
      "Adding chunk 1790 to the vector store...\n",
      "Adding chunk 1800 to the vector store...\n",
      "Adding chunk 1810 to the vector store...\n",
      "Adding chunk 1820 to the vector store...\n",
      "Adding chunk 1830 to the vector store...\n",
      "Adding chunk 1840 to the vector store...\n",
      "Adding chunk 1850 to the vector store...\n",
      "Adding chunk 1860 to the vector store...\n",
      "Adding chunk 1870 to the vector store...\n",
      "Adding chunk 1880 to the vector store...\n",
      "Adding chunk 1890 to the vector store...\n",
      "Adding chunk 1900 to the vector store...\n",
      "Adding chunk 1910 to the vector store...\n",
      "Adding chunk 1920 to the vector store...\n",
      "Adding chunk 1930 to the vector store...\n",
      "Adding chunk 1940 to the vector store...\n",
      "Adding chunk 1950 to the vector store...\n",
      "Adding chunk 1960 to the vector store...\n",
      "Adding chunk 1970 to the vector store...\n",
      "Adding chunk 1980 to the vector store...\n",
      "Adding chunk 1990 to the vector store...\n",
      "Adding chunk 2000 to the vector store...\n",
      "Adding chunk 2010 to the vector store...\n",
      "Adding chunk 2020 to the vector store...\n",
      "Adding chunk 2030 to the vector store...\n",
      "Adding chunk 2040 to the vector store...\n",
      "Adding chunk 2050 to the vector store...\n",
      "Adding chunk 2060 to the vector store...\n",
      "Adding chunk 2070 to the vector store...\n",
      "Adding chunk 2080 to the vector store...\n",
      "Adding chunk 2090 to the vector store...\n",
      "Adding chunk 2100 to the vector store...\n",
      "Adding chunk 2110 to the vector store...\n",
      "Adding chunk 2120 to the vector store...\n",
      "Adding chunk 2130 to the vector store...\n",
      "Adding chunk 2140 to the vector store...\n",
      "Adding chunk 2150 to the vector store...\n",
      "Adding chunk 2160 to the vector store...\n",
      "Adding chunk 2170 to the vector store...\n",
      "Adding chunk 2180 to the vector store...\n",
      "Adding chunk 2190 to the vector store...\n",
      "Adding chunk 2200 to the vector store...\n",
      "Adding chunk 2210 to the vector store...\n",
      "Adding chunk 2220 to the vector store...\n",
      "Adding chunk 2230 to the vector store...\n",
      "Adding chunk 2240 to the vector store...\n",
      "Adding chunk 2250 to the vector store...\n",
      "Adding chunk 2260 to the vector store...\n",
      "Adding chunk 2270 to the vector store...\n",
      "Adding chunk 2280 to the vector store...\n",
      "Adding chunk 2290 to the vector store...\n",
      "Adding chunk 2300 to the vector store...\n",
      "Adding chunk 2310 to the vector store...\n",
      "Adding chunk 2320 to the vector store...\n",
      "Adding chunk 2330 to the vector store...\n",
      "Adding chunk 2340 to the vector store...\n",
      "Adding chunk 2350 to the vector store...\n",
      "Adding chunk 2360 to the vector store...\n",
      "Adding chunk 2370 to the vector store...\n",
      "Adding chunk 2380 to the vector store...\n",
      "Adding chunk 2390 to the vector store...\n",
      "Adding chunk 2400 to the vector store...\n",
      "Adding chunk 2410 to the vector store...\n",
      "Adding chunk 2420 to the vector store...\n",
      "Adding chunk 2430 to the vector store...\n",
      "Adding chunk 2440 to the vector store...\n",
      "Adding chunk 2450 to the vector store...\n",
      "Adding chunk 2460 to the vector store...\n",
      "Adding chunk 2470 to the vector store...\n",
      "Adding chunk 2480 to the vector store...\n",
      "Adding chunk 2490 to the vector store...\n",
      "Adding chunk 2500 to the vector store...\n",
      "Adding chunk 2510 to the vector store...\n",
      "Adding chunk 2520 to the vector store...\n",
      "Adding chunk 2530 to the vector store...\n",
      "Adding chunk 2540 to the vector store...\n",
      "Adding chunk 2550 to the vector store...\n",
      "Adding chunk 2560 to the vector store...\n",
      "Adding chunk 2570 to the vector store...\n",
      "Adding chunk 2580 to the vector store...\n",
      "Adding chunk 2590 to the vector store...\n",
      "Adding chunk 2600 to the vector store...\n",
      "Adding chunk 2610 to the vector store...\n",
      "Adding chunk 2620 to the vector store...\n",
      "Adding chunk 2630 to the vector store...\n",
      "Adding chunk 2640 to the vector store...\n",
      "Adding chunk 2650 to the vector store...\n",
      "Adding chunk 2660 to the vector store...\n",
      "Adding chunk 2670 to the vector store...\n",
      "Adding chunk 2680 to the vector store...\n",
      "Adding chunk 2690 to the vector store...\n",
      "Adding chunk 2700 to the vector store...\n",
      "Adding chunk 2710 to the vector store...\n",
      "Adding chunk 2720 to the vector store...\n",
      "Adding chunk 2730 to the vector store...\n",
      "Adding chunk 2740 to the vector store...\n"
     ]
    }
   ],
   "source": [
    "contexts = list(df_contexts[\"squad_context\"].values)\n",
    "if CHUNK_SQUAD_DATASET:    \n",
    "    deh_vector_store.chunk_squad_dataset(contexts, dataset, CHUNK_SIZE, CHUNK_OVERLAP)\n",
    "else:\n",
    "    print(\"Chunking not foreseen. Skipping chunking.\")\n",
    "\n",
    "# Intiialize the Chroma vector store\n",
    "vector_store = deh_vector_store.get_vector_store(DEFAULT_CHROMA_PREFIX, DEFAULT_CHUNKING_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading qas with contexts data (if data is not to be restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESTORE_QAS_WITH_CONTEXTS is True. Skipping loading qas_with_contexts from the CSV file.\n"
     ]
    }
   ],
   "source": [
    "qas_with_contexts_csv_file_path = f\"{DATA_ROOT}/qas_with_contexts_k{VECTOR_STORE_TOP_K}_cs{CHUNK_SIZE}_{DEFAULT_CHUNKING_METHOD}.csv\"\n",
    "\n",
    "# If not restoring qas_with_contexts from the CSV file, then read\n",
    "# the data from the csv file (i.e. it exists and is correct)\n",
    "if not RESTORE_QAS_WITH_CONTEXTS:\n",
    "    # Loading the question contexts from the CSV file\n",
    "    \n",
    "    #qas_with_contexts_csv_file_path = f\"{DATA_ROOT}/qas_with_contexts_k{VECTOR_STORE_TOP_K}_{DEFAULT_CHUNKING_METHOD}.csv\\n\"\n",
    "    print(f\"Loading qas_with_contexts from the CSV file: {qas_with_contexts_csv_file_path}\\n...\")\n",
    "    \n",
    "    try:\n",
    "        df_qas_with_contexts = pd.read_csv(qas_with_contexts_csv_file_path) #, names=column_names)\n",
    "        print(f\"Loaded qas_with_contexts from {qas_with_contexts_csv_file_path}\\n...\")\n",
    "    except Exception as e:  # Catch all exceptions\n",
    "        print(f\"An error has occurred: {e}\")\n",
    "        print(f\"Failed to load qas_with_contexts from {qas_with_contexts_csv_file_path}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # drop the answer column if it exists, since it leads to duplicates\n",
    "    if 'answer' in df_qas_with_contexts.columns:\n",
    "        df_qas_with_contexts = df_qas_with_contexts.drop(columns=['answer'])\n",
    "\n",
    "    df_qas_with_contexts = df_qas_with_contexts.drop_duplicates()\n",
    "    print(f\"Rows in dataframe df_qas_with_contexts: {len(df_qas_with_contexts)}\")\n",
    "    hyde_articles_cnt = df_qas_with_contexts['hyde_article'].notna().sum()\n",
    "    hyde_based_contexts_cnt = df_qas_with_contexts['hyde_based_context'].notna().sum()\n",
    "    print(f\"Number of questions with Hyde articles: {hyde_articles_cnt}\")\n",
    "    print(f\"Number of questions with Hyde based contexts: {hyde_based_contexts_cnt}\")\n",
    "else:\n",
    "    print(f\"RESTORE_QAS_WITH_CONTEXTS is True. Skipping loading qas_with_contexts from the CSV file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restore qas with contexts (if configured); alternatively refreseh contexts in existing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_df_qas_with_contexts_file(qas_with_contexts_csv_file_path, df_qas):\n",
    "\n",
    "    # Add columns hyde_article, question_context, hyde_based_context to df_qas_with_contexts\n",
    "    if not 'hyde_article' in df_qas.columns:\n",
    "        df_qas['hyde_article'] = np.nan\n",
    "    if not 'question_context' in df_qas.columns:\n",
    "        df_qas['question_context'] = np.nan\n",
    "    if not 'hyde_based_context' in df_qas.columns:\n",
    "        df_qas['hyde_based_context'] = np.nan\n",
    "\n",
    "    # Get Hyde data\n",
    "    hyde_based_context_path = f\"{HYDE_BASED_CONTEXTS_ROOT}/hyde_based_contexts.csv\"\n",
    "    df_hyde_based_contexts = pd.read_csv(hyde_based_context_path)\n",
    "\n",
    "    print(f\"Rows in dataframe df_hyde_based_contexts: {len(df_hyde_based_contexts)}\")\n",
    "    hyde_articles_cnt = df_hyde_based_contexts['hyde_article'].notna().sum()\n",
    "    hyde_based_contexts_cnt = df_hyde_based_contexts['hyde_based_context'].notna().sum()\n",
    "\n",
    "    # Merge df_qas with df_hyde_based_contexts based on the 'qid' column\n",
    "    merged = df_qas.merge(df_hyde_based_contexts, on='qid', how='left', suffixes=('', '_df_hyde_based_contexts'))\n",
    "    df_qas['hyde_article'] = merged['hyde_article_df_hyde_based_contexts']\n",
    "\n",
    "    print(f\"Number of questions with Hyde articles: {hyde_articles_cnt}\")\n",
    "    print(f\"Number of questions with Hyde based contexts: {hyde_based_contexts_cnt}\")\n",
    "\n",
    "    df_qas.to_csv(qas_with_contexts_csv_file_path, header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in dataframe df_hyde_based_contexts: 3924\n",
      "Number of questions with Hyde articles: 3924\n",
      "Number of questions with Hyde based contexts: 0\n",
      "Re-Generating contexts for the dataset and persisting the data...\n",
      "Processing question 0...\n",
      "Processing question 100...\n",
      "Processing question 200...\n",
      "Processing question 300...\n",
      "Processing question 400...\n",
      "Processing question 500...\n",
      "Processing question 600...\n",
      "Processing question 700...\n",
      "Processing question 800...\n",
      "Processing question 900...\n",
      "Processing question 1000...\n",
      "Processing question 1100...\n",
      "Processing question 1200...\n",
      "Processing question 1300...\n",
      "Processing question 1400...\n",
      "Processing question 1500...\n",
      "Processing question 1600...\n",
      "Processing question 1700...\n",
      "Processing question 1800...\n",
      "Processing question 1900...\n",
      "Processing question 2000...\n",
      "Processing question 2100...\n",
      "Processing question 2200...\n",
      "Processing question 2300...\n",
      "Processing question 2400...\n",
      "Processing question 2500...\n",
      "Processing question 2600...\n",
      "Processing question 2700...\n",
      "Processing question 2800...\n",
      "Processing question 2900...\n",
      "Processing question 3000...\n",
      "Processing question 3100...\n",
      "Processing question 3200...\n",
      "Processing question 3300...\n",
      "Processing question 3400...\n",
      "Processing question 3500...\n",
      "Processing question 3600...\n",
      "Processing question 3700...\n",
      "Processing question 3800...\n",
      "Processing question 3900...\n",
      "Processing question 4000...\n",
      "Processing question 4100...\n",
      "Processing question 4200...\n",
      "Processing question 4300...\n",
      "Processing question 4400...\n",
      "Processing question 4500...\n",
      "Processing question 4600...\n",
      "Processing question 4700...\n",
      "Processing question 4800...\n",
      "Processing question 4900...\n",
      "Processing question 5000...\n",
      "Processing question 5100...\n",
      "Processing question 5200...\n",
      "Processing question 5300...\n",
      "Processing question 5400...\n",
      "Processing question 5500...\n",
      "Processing question 5600...\n",
      "Processing question 5700...\n",
      "Processing question 5800...\n",
      "Processing question 5900...\n",
      "Processing question 6000...\n",
      "Processing question 6100...\n",
      "Processing question 6200...\n",
      "Processing question 6300...\n",
      "Processing question 6400...\n",
      "Processing question 6500...\n",
      "Processing question 6600...\n",
      "Processing question 6700...\n",
      "Processing question 6800...\n",
      "Processing question 6900...\n",
      "Processing question 7000...\n",
      "Processing question 7100...\n",
      "Processing question 7200...\n",
      "Processing question 7300...\n",
      "Processing question 7400...\n",
      "Processing question 7500...\n",
      "Processing question 7600...\n",
      "Processing question 7700...\n",
      "Processing question 7800...\n",
      "Processing question 7900...\n",
      "Processing question 8000...\n",
      "Processing question 8100...\n",
      "Processing question 8200...\n",
      "Processing question 8300...\n",
      "Processing question 8400...\n",
      "Processing question 8500...\n",
      "Processing question 8600...\n",
      "Processing question 8700...\n",
      "Processing question 8800...\n",
      "Processing question 8900...\n",
      "Processing question 9000...\n",
      "Processing question 9100...\n",
      "Processing question 9200...\n",
      "Processing question 9300...\n",
      "Processing question 9400...\n",
      "Processing question 9500...\n",
      "Processing question 9600...\n",
      "Processing question 9700...\n",
      "Processing question 9800...\n",
      "Processing question 9900...\n",
      "Processing question 10000...\n",
      "Processing question 10100...\n",
      "Processing question 10200...\n",
      "Processing question 10300...\n",
      "Processing question 10400...\n",
      "Processing question 10500...\n",
      "Processing question 10600...\n",
      "Processing question 10700...\n",
      "Processing question 10800...\n",
      "Processing question 10900...\n",
      "Processing question 11000...\n",
      "Processing question 11100...\n",
      "Processing question 11200...\n",
      "Processing question 11300...\n",
      "Processing question 11400...\n",
      "Processing question 11500...\n",
      "Processing question 11600...\n",
      "Processing question 11700...\n",
      "Processing question 11800...\n"
     ]
    }
   ],
   "source": [
    "# TODO --> check if qas_with_contexts file already exists\n",
    "\n",
    "if RESTORE_QAS_WITH_CONTEXTS:\n",
    "    restore_df_qas_with_contexts_file(qas_with_contexts_csv_file_path, df_qas)\n",
    "\n",
    "# Refresh question contexts (normal contexts and hyde-based contexts)\n",
    "# TODO: might be useful to first empty the two columns in the dataframe\n",
    "if RESTORE_QAS_WITH_CONTEXTS or REFRESH_QUESTION_CONTEXTS or REFRESH_HYDE_CONTEXTS:\n",
    "    print(f\"Re-Generating contexts for the dataset and persisting the data...\")\n",
    "    list_of_qas = df_qas.to_dict(orient='records')\n",
    "\n",
    "    for i, qa in enumerate(list_of_qas):\n",
    "        # print(i)\n",
    "        if i %100 == 0:\n",
    "            print(f\"Processing question {i}...\")\n",
    "\n",
    "        if RESTORE_QAS_WITH_CONTEXTS or REFRESH_QUESTION_CONTEXTS:\n",
    "            question = qa[\"question\"]\n",
    "            \n",
    "            top_docs = vector_store.similarity_search(\n",
    "                query = question,\n",
    "                k = VECTOR_STORE_TOP_K,\n",
    "            )\n",
    "            qa[\"question_context\"] = \"\\n\\n\".join([top_doc.page_content for top_doc in top_docs])\n",
    "\n",
    "        if RESTORE_QAS_WITH_CONTEXTS or REFRESH_HYDE_CONTEXTS:\n",
    "            hyde_article = qa[\"hyde_article\"]\n",
    "            #print(f\"hyde_article: {hyde_article}\")\n",
    "            if pd.isna(hyde_article):\n",
    "                hyde_article = \"\"\n",
    "            elif len(hyde_article) == 0:\n",
    "                hyde_article = \"\"\n",
    "            else:\n",
    "                top_docs = vector_store.similarity_search(\n",
    "                    query = hyde_article,\n",
    "                    k = VECTOR_STORE_TOP_K,\n",
    "                )\n",
    "\n",
    "                qa[\"hyde_based_context\"] = \"\\n\\n\".join([top_doc.page_content for top_doc in top_docs])\n",
    "\n",
    "    df_qas = pd.DataFrame(list_of_qas)\n",
    "    df_qas_with_contexts = df_qas.copy()\n",
    "    df_qas.to_csv(qas_with_contexts_csv_file_path, header=True, index=False)\n",
    "else:\n",
    "    print(f\"Not restoring df_qas_with_contexts or refresh of the contexts...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show names of all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "print(\"Names of Dataframes and their lenghts:\\n\")\n",
    "global_keys_copy = copy.deepcopy(list(globals().keys()))\n",
    "\n",
    "my_l = [{n: len(globals()[n])} for n in global_keys_copy if n.startswith(\"df_\")]\n",
    "df_dfs = pd.DataFrame([(k, v) for d in my_l for k, v in d.items()], columns=['df name', 'rows'])\n",
    "df_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions that are needed for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the runnable chain\n",
    "def get_runnable_chain(current_query_prompt, llm):\n",
    "    runnable_chain = RunnableSequence(current_query_prompt | llm)\n",
    "    return runnable_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Hyde context for a question\n",
    "def get_hyde_based_context(question):\n",
    "    hyde_based_context = df_qas_with_contexts[df_qas_with_contexts[\"question\"] == question]\n",
    "    if hyde_based_context.empty:\n",
    "        return None\n",
    "    else:\n",
    "        return hyde_based_context[\"hyde_based_context\"].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "\n",
    "# Get the metrics for a set of predictions (preds) that have been generated in a run\n",
    "def get_squad_metrics(dataset, preds, verbose=False):\n",
    "    squad_metrics = squad_scoring.calc_squad_metrics(dataset, preds);\n",
    "    return squad_metrics[\"precision\"], squad_metrics[\"recall\"], squad_metrics[\"f1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and confidence interval for a list of scores\n",
    "# TODO: Check if this is calculation is correct !!\n",
    "def calculate_mean_confidence_interval(scores_l):\n",
    "\n",
    "    # Calculate mean\n",
    "    mean = np.mean(scores_l)\n",
    "\n",
    "    # Calculate 95% confidence interval\n",
    "    sample_std_dev = np.std(scores_l, ddof=1)\n",
    "    margin_of_error = 1.96 * sample_std_dev\n",
    "    ci = (max(mean - margin_of_error, 0), min(mean + margin_of_error, 100))\n",
    "\n",
    "    return mean, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a histogram for a list of scores and persist it\n",
    "def generate_histogram(scores_l, mean, ci, results_folder_name, experiment_name):\n",
    "\n",
    "    plt.clf\n",
    "    plt.hist(scores_l, bins=30, density=False, edgecolor='black', alpha=0.6, color = 'lightblue' ) # color='aquamarine')\n",
    "    plt.xlim(0, 100)\n",
    "\n",
    "    plt.title(f\"F1-Scores for {experiment_name} - (Bootstraps: {BOOTSTRAPS_N:,} - Sample Size: {SAMPLE_SIZE:,})\", fontsize=10)\n",
    "    plt.xlabel(\"F1-Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Add a vertical line for the mean\n",
    "    max_len = 6\n",
    "    mean_label = f\"{mean: .2f}\".rjust(max_len)\n",
    "    plt.axvline(mean, color='red', linestyle='dotted', linewidth=2, label=f'Mean F1:          {mean_label}')\n",
    "\n",
    "    # Add vertical lines for the 95% confidence interval\n",
    "    lower = f\"{ci[0]: .2f}\".rjust(max_len)\n",
    "    upper = f\"{ci[1]: .2f}\".rjust(max_len)\n",
    "    plt.axvline(ci[0], color='orange', linestyle='dashdot', linewidth=1.5, label=f\"95% CI Lower:  {lower}\")\n",
    "    plt.axvline(ci[1], color='orange', linestyle='dashdot', linewidth=1.5, label=f\"95% CI Upper:  {upper}\\n\")\n",
    "\n",
    "    ax = plt.gca()  # Get current axis\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(10))  # Set major ticks every 10 units\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(5))   # Set minor ticks every 5 units\n",
    "    # ax.yaxis.set_major_locator(MultipleLocator(10))  # Example: Major ticks every 5 units on the y-axis\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n",
    "    \n",
    "    # Customize grid for major and minor ticks\n",
    "    ax.grid(which='major', color='gray', linestyle='--', linewidth=0.5)\n",
    "    ax.grid(which='minor', color='lightgray', linestyle=':', linewidth=0.5)\n",
    "\n",
    "    # Add a legend\n",
    "\n",
    "    # Add additional text to the legend\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    model_info_line = Line2D([0], [0], color='none', label=f\"LLM Model: {CHAT_MODEL_NAME}\")\n",
    "    handles.append(model_info_line)\n",
    "    labels.append(f\"LLM Model: {CHAT_MODEL_NAME}\")\n",
    "    handles.append(model_info_line)\n",
    "    labels.append(f\"max_tokens={MAX_TOKENS:,}\")\n",
    "    handles.append(model_info_line)\n",
    "    labels.append(f\"chunk_size={f\"{CHUNK_SIZE:,}\"}\")\n",
    "    handles.append(model_info_line) \n",
    "    labels.append(f\"K={VECTOR_STORE_TOP_K} / {DEFAULT_CHUNKING_METHOD}\")\n",
    "\n",
    "    # TODO: Clean this code\n",
    "    plt.legend(prop={'family': 'monospace', 'size': 9})\n",
    "    plt.legend(handles, labels, loc='upper right', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_folder_name, f\"{experiment_name}_{BOOTSTRAPS_N}_{SAMPLE_SIZE}\"))\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LLM as a Judge functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_answer_tuple(input_string):\n",
    "    # Trim whitespace\n",
    "    parts = input_string.strip()\n",
    "    # Remove parentheses\n",
    "    parts = parts.strip(\"()\")\n",
    "    # Split on comma\n",
    "    parts = parts.split(\", \")\n",
    "    if len(parts) != 2:\n",
    "        #raise ValueError(\"Invalid answer string\")\n",
    "        return (\"NO\", 0)\n",
    "\n",
    "    answer = parts[0].strip().upper()  # \"Yes\" or \"No\"\n",
    "    if answer not in [\"YES\", \"NO\"]:\n",
    "        #raise ValueError(\"Invalid answer string\")\n",
    "        return (\"NO\", 0)\n",
    "    try:\n",
    "        score = float(parts[1])  # Convert score to a float\n",
    "    except ValueError:\n",
    "        return (\"NO\", 0)\n",
    "    \n",
    "    return (answer, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_verdict(judge_verdicts):\n",
    "\n",
    "    judge_answers = judge_verdicts[0]\n",
    "    yes_count = judge_answers.count('YES')\n",
    "    no_count = judge_answers.count('NO')\n",
    "\n",
    "    if no_count > yes_count:\n",
    "        return \"NO\", 0.0\n",
    "    \n",
    "    judge_scores = list(judge_verdicts[1])\n",
    "    return \"YES\", sum(judge_scores) / yes_count\n",
    "\n",
    "def get_majority_verditcs(all_judge_answers, all_judge_scores):\n",
    "\n",
    "    majority_verdicts = []\n",
    "    for per_question_judge_verdicts in zip(zip(*all_judge_answers), zip(*all_judge_scores)):\n",
    "        majority_verdict = get_majority_verdict(per_question_judge_verdicts)\n",
    "        majority_verdicts.append(majority_verdict)\n",
    "\n",
    "    return majority_verdicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_judges_verdicts(sample_ldict, experiment_name, hyde_context_needed=False):\n",
    "    judge_current_query_prompt = deh_prompts.query_prompts[4]\n",
    "    print(f\"judge_current_query_prompt = {judge_current_query_prompt.template}\\n\")\n",
    "    for ele in sample_ldict:\n",
    "        print(ele)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    all_judge_answers = []\n",
    "    all_judge_scores = []\n",
    "\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    for judge_i, judge_llm in enumerate(judge_llms):\n",
    "        judge_chain = judge_current_query_prompt | get_llm(judge_current_query_prompt, True, judge_llm)\n",
    "        judge_answers = []\n",
    "        judge_scores = []\n",
    "\n",
    "        for i, qa in enumerate(sample_ldict):\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Processing question {i} for judge {judge_i}...\")\n",
    "\n",
    "            question = qa[\"question\"]\n",
    "            context = qa[\"question_context\"]\n",
    "            if hyde_context_needed:\n",
    "                hyde_based_context = qa[\"hyde_based_context\"]\n",
    "                context = \"\\n\\n\".join([context, hyde_based_context])\n",
    "            answer_key = experiment_name.lower() + \"_llm_answer\"\n",
    "            answer = qa[answer_key]\n",
    "\n",
    "            response = judge_chain.invoke({\"context\": context, \"question\": question, \"answer\": answer})\n",
    "            a, s = convert_string_to_answer_tuple(response.content)\n",
    "            judge_answers.append(a)\n",
    "            judge_scores.append(s)\n",
    "            \n",
    "        all_judge_answers.append(judge_answers)\n",
    "        all_judge_scores.append(judge_scores)\n",
    "\n",
    "    final_judges_verdicts = get_majority_verditcs(all_judge_answers, all_judge_scores)\n",
    "    return final_judges_verdicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions for Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current timestamp and format the start timestamp as a string\n",
    "def get_timestamp_as_string():\n",
    "    start_timestamp = datetime.now()\n",
    "    start_timestamp_str = start_timestamp.strftime('%Y%m%d_%H%M%S')\n",
    "    return start_timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(qas, query_prompt_idx, experiment_name, context_needed=False,\n",
    "                     hyde_context_needed=False, suppress_answers=False):\n",
    "\n",
    "    # Create the chain\n",
    "    current_query_prompt = deh_prompts.query_prompts[query_prompt_idx]\n",
    "    print(f\"current_query_prompt = {current_query_prompt.template}\\n\")\n",
    "    llm = get_llm(current_query_prompt)\n",
    "    runnable_chain = get_runnable_chain(current_query_prompt, llm)\n",
    "\n",
    "    # Generate the LLM answers for all questions and calculate per-answer metrics \n",
    "    # add each answer to the all_preds\n",
    "    preds = {}\n",
    "    all_preds= {}\n",
    "\n",
    "    for i, qa in enumerate(qas):\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing question {i}...\")\n",
    "\n",
    "        qid = qa[\"qid\"]\n",
    "        question = qa[\"question\"]\n",
    "\n",
    "        if context_needed:\n",
    "            if experiment_name in [\"BASIC_RAG_HYDE\"]:\n",
    "                context = qa[\"hyde_based_context\"]\n",
    "            elif experiment_name in [\"FULL_RAG\"]:\n",
    "                context = qa[\"question_context\"] + \"\\n\\n\" + qa[\"hyde_based_context\"]\n",
    "            elif experiment_name in [\"BASIC_RAG\", \"BASIC_RAG_DONT_LIE\",\n",
    "                                     \"BASIC_RAG_SUPPRESS_ANSWERS\", \"BASIC_RAG_SEMANTIC\"]:\n",
    "                context = qa[\"question_context\"]\n",
    "            response = runnable_chain.invoke({\"question\": question, \"context\": context})\n",
    "        else:\n",
    "            response = runnable_chain.invoke({\"question\": question})\n",
    "\n",
    "        llm_answer = response.content\n",
    "\n",
    "        if \"DONT KNOW\" in llm_answer.upper() or llm_answer.upper().startswith(\"NO CONTEXT PROVIDED\") or llm_answer.upper().startswith(\"NO INFORMATION GIVEN\"):  \n",
    "            llm_answer = \"\"\n",
    "\n",
    "        preds[qid] = llm_answer\n",
    "        all_preds[qid] = llm_answer\n",
    "\n",
    "        scores = squad_scoring.calc_squad_metrics(dataset, preds)\n",
    "        f1 = scores[\"f1\"]\n",
    "        precision = scores[\"precision\"]\n",
    "        recall = scores[\"recall\"]\n",
    "\n",
    "        preds = {}\n",
    "        qa[f\"{experiment_name.lower()}_llm_answer\"] = llm_answer\n",
    "        qa[f\"{experiment_name.lower()}_f1\"] = f1\n",
    "        qa[f\"{experiment_name.lower()}_precision\"] = precision\n",
    "        qa[f\"{experiment_name.lower()}_recall\"] = recall\n",
    "\n",
    "    if suppress_answers:\n",
    "        final_judges_verdicts = get_final_judges_verdicts(qas, experiment_name, hyde_context_needed)\n",
    "        for i, qa in enumerate(qas):\n",
    "            if final_judges_verdicts[i][0] == \"NO\":\n",
    "                qa[f\"{experiment_name.lower()}_llm_answer\"] = \"\"\n",
    "            else:\n",
    "                if final_judges_verdicts[i][1] < JUDGES_SUPPRESS_THRESHOLD:\n",
    "                    qa[f\"{experiment_name.lower()}_llm_answer\"] = \"\"\n",
    "\n",
    "    return all_preds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_results(results_folder_name, experiment_name, df):\n",
    "\n",
    "    df.to_csv(f\"{results_folder_name}/qas_{experiment_name.lower()}_scores.csv\", header=True, index=False)\n",
    "    df[['qid', 'question', f\"{experiment_name.lower()}_llm_answer\"]].to_csv(f\"{results_folder_name}/qas_{experiment_name.lower()}_answers.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_experiments_config(results_folder_name, experiment_name, experiment_mean, experiment_ci, execution_time):\n",
    "\n",
    "    params_str = f\"Experiment: {experiment_name}\\n\"\n",
    "    params_str = params_str + f\"{datetime.now()}\\n\"\n",
    "    params_str = params_str + f\"Execution duration in minutes: {round(execution_time/60,2)}\\n\"\n",
    "    params_str = params_str + \"================================================\\n\\n\"\n",
    "\n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"F1 mean: {experiment_mean}\\n\"\n",
    "    params_str = params_str + f\"95% CI ({experiment_ci[0]}, {experiment_ci[1]})\\n\\n\"\n",
    "\n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"DATA_ROOT = {DATA_ROOT}\\n\"\n",
    "    params_str = params_str + f\"RESULTS_ROOT = {RESULTS_ROOT}\\n\"\n",
    "    params_str = params_str + f\"HYDE_BASED_CONTEXTS_ROOT  = {HYDE_BASED_CONTEXTS_ROOT}\\n\"\n",
    "    params_str = params_str + f\"data_file = {DATA_ROOT}/dev-v2.0.json\\n\\n\"\n",
    "    \n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"CHROMA_ROOT               = {CHROMA_ROOT}\\n\"\n",
    "    params_str = params_str + f\"VECTOR_STORE_TOP_K        = {VECTOR_STORE_TOP_K}\\n\"\n",
    "    params_str = params_str + f\"CHUNK_SIZE                = {CHUNK_SIZE}\\n\"\n",
    "    params_str = params_str + f\"CHUNK_OVERLAP             = {CHUNK_OVERLAP}\\n\"\n",
    "    params_str = params_str + f\"DEFAULT_CHROMA_PREFIX     = {DEFAULT_CHROMA_PREFIX}\\n\"\n",
    "    params_str = params_str + f\"DEFAULT_CHUNKING_METHOD   = {DEFAULT_CHUNKING_METHOD}\\n\"\n",
    "    params_str = params_str + f\"CHUNK_SQUAD_DATASET       = {CHUNK_SQUAD_DATASET}\\n\\n\"\n",
    "    \n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"REFRESH_QUESTION_CONTEXTS = {REFRESH_QUESTION_CONTEXTS}\\n\"\n",
    "    params_str = params_str + f\"REFRESH_HYDE_CONTEXTS     = {REFRESH_HYDE_CONTEXTS}\\n\"\n",
    "    # params_str = params_str + f\"READ_QAS_FROM_FILE        = {READ_QAS_FROM_FILE}\\n\"\n",
    "    params_str = params_str + f\"RESTORE_QAS_WITH_CONTEXTS = {RESTORE_QAS_WITH_CONTEXTS}\\n\\n\"\n",
    "\n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"        \n",
    "    params_str = params_str + f\"SAMPLE_SIZE  = {SAMPLE_SIZE}\\n\"\n",
    "    params_str = params_str + f\"BOOTSTRAPS_N = {BOOTSTRAPS_N}\\n\\n\"\n",
    "\n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_0  = {LLM_MODEL_NAME_0}\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_1  = {LLM_MODEL_NAME_1}\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_2  = {LLM_MODEL_NAME_2}\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_3  = {LLM_MODEL_NAME_3}\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_4  = {LLM_MODEL_NAME_4}\\n\"\n",
    "    params_str = params_str + f\"LLM_MODEL_NAME_5  = {LLM_MODEL_NAME_5}\\n\"\n",
    "    params_str = params_str + f\"CHAT_MODEL_NAME   = {CHAT_MODEL_NAME}\\n\\n\"\n",
    "    \n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    params_str = params_str + f\"MAX_TOKENS        = {MAX_TOKENS}\\n\"\n",
    "    params_str = params_str + f\"TEMPERATURE       = {TEMPERATURE}\\n\"\n",
    "    params_str = params_str + f\"TOP_P             = {TOP_P}\\n\"\n",
    "    params_str = params_str + f\"FREQUENCY_PENALTY = {FREQUENCY_PENALTY}\\n\"\n",
    "    params_str = params_str + f\"PRESENCE_PENALTY  = {PRESENCE_PENALTY}\\n\\n\"\n",
    "\n",
    "\n",
    "    params_str = params_str + \"--------------------------------------------------------\\n\"\n",
    "    judges = [llm_models[judge_i] for judge_i in judge_llms]\n",
    "    params_str = params_str + f\"Judge LLMS = {judges}\\n\"\n",
    "    params_str = params_str + f\"JUDGES_SUPPRESS_THRESHOLD   = {JUDGES_SUPPRESS_THRESHOLD}\\n\\n\"\n",
    "\n",
    "    with open(f\"{results_folder_name}/experiments_config_{experiment_name.lower()}.txt\", 'w') as f:\n",
    "        f.write(params_str)\n",
    "\n",
    "    print(\"Persisting the experiment config done...\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_scores(scores_l, clip_perc):\n",
    "    scores_sorted_l = sorted(scores_l)\n",
    "\n",
    "    clip_cnt = int(len(scores_sorted_l) * clip_perc / 100)\n",
    "    print(f\"clip_cnt: {clip_cnt}\")\n",
    "\n",
    "    # Now clip both ends by clip_perc percent\n",
    "    clipped_scores_l = scores_sorted_l[clip_cnt:-clip_cnt] if clip_cnt > 0 else scores_sorted_l\n",
    "    return clipped_scores_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bootstrapping(scores_l, results_folder_name, experiment_name, bootstraps_n = BOOTSTRAPS_N):\n",
    "    \n",
    "    mu_hats = []\n",
    "    n = len(scores_l)\n",
    "    scores_l = clip_scores(scores_l, 2.5)\n",
    "\n",
    "    for i in range(bootstraps_n):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing sample {i}...\")\n",
    "        bootstrap_sample = random.choices(scores_l, k=n) # sample with replacement\n",
    "        mu_hat = np.mean(bootstrap_sample)\n",
    "        mu_hats.append(mu_hat)\n",
    "\n",
    "    bootstraps_mean, ci = calculate_mean_confidence_interval(mu_hats)\n",
    "    plt = generate_histogram(mu_hats, bootstraps_mean, ci, results_folder_name, experiment_name)\n",
    "    plt.show();\n",
    "    return bootstraps_mean, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results_folder(experiment_name):\n",
    "    start_timestamp_str = get_timestamp_as_string()\n",
    "    results_folder_name = f\"{RESULTS_ROOT}/{experiment_name}/results_{start_timestamp_str}\"\n",
    "    if not os.path.exists(results_folder_name):\n",
    "        os.makedirs(results_folder_name, exist_ok=True)\n",
    "    return results_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_experiment(qas, experiment_name, query_prompt_idx, \n",
    "                       context_needed=False, hyde_context_needed=False, \n",
    "                       suppress_answers=False):\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    print(f\"============= Creating results folder for {experiment_name} =============\")\n",
    "    results_folder_name = create_results_folder(experiment_name)\n",
    "    \n",
    "    print(f\"============= Calculating scores for {experiment_name} =============\")\n",
    "    print(f\"SAMPLE_SIZE: {SAMPLE_SIZE}\\n\")\n",
    "    all_preds = calculate_scores(qas, query_prompt_idx, experiment_name, context_needed, \n",
    "                                 hyde_context_needed, suppress_answers)\n",
    "\n",
    "    print(f\"============= Persisting results for {experiment_name} =============\")\n",
    "    df = pd.DataFrame(qas)\n",
    "    persist_results(results_folder_name, experiment_name, df)\n",
    "    \n",
    "    print(f\"\\n============= Bootstrapping for {experiment_name} =============\")\n",
    "    print(f\"BOOTSTRAPS_N: {BOOTSTRAPS_N}\")\n",
    "\n",
    "    experiment_mean, experiment_ci = do_bootstrapping(df[f\"{experiment_name.lower()}_f1\"].dropna().tolist(), results_folder_name, experiment_name, BOOTSTRAPS_N)\n",
    "    \n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    execution_times_entry = {}\n",
    "    execution_times_entry[\"experiment_name\"] = experiment_name\n",
    "    execution_times_entry[\"execution_time\"] = execution_time\n",
    "    execution_times_entry[\"sample_size\"] = SAMPLE_SIZE\n",
    "    execution_times_entry[\"bootstrap_n\"] = BOOTSTRAPS_N\n",
    "    execution_times_l.append(execution_times_entry)\n",
    "\n",
    "    print(f\"Will now persist the experiment configuration for {experiment_name}...\")\n",
    "    persist_experiments_config(results_folder_name, experiment_name, experiment_mean, experiment_ci, execution_time)\n",
    "\n",
    "    return execution_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a sample from df_cas_with_contexts for bootstrapping and bootstrapping with Hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qas_for_bootstrapping = df_qas_with_contexts[['qid', 'question', 'question_context', 'hyde_based_context']]\n",
    "df_qas_for_bootstrapping_sample = df_qas_for_bootstrapping.sample(n=SAMPLE_SIZE, replace=True, random_state=42)\n",
    "ldict_qas_for_boostrapping_sample = df_qas_for_bootstrapping_sample.to_dict(orient='records')\n",
    "\n",
    "df_qas_for_hyde_bootstrapping = df_qas_for_bootstrapping[df_qas_for_bootstrapping['hyde_based_context'].notna()]\n",
    "df_qas_for_hyde_bootstrapping_sample = df_qas_for_hyde_bootstrapping.sample(n=SAMPLE_SIZE, replace=True, random_state=42)\n",
    "ldict_qas_for_hyde_bootstrapping_sample = df_qas_for_hyde_bootstrapping_sample.to_dict(orient='records')   \n",
    "\n",
    "sample_ldicts = [ldict_qas_for_boostrapping_sample, ldict_qas_for_hyde_bootstrapping_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conducting all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all experiments and execute them one by one if they are included\n",
    "for index, row in df_experiments.iterrows():\n",
    "    if not row[\"include\"]:\n",
    "        continue\n",
    "\n",
    "    sample_ldict = sample_ldicts[row[\"sample_ldicts_idx\"]]\n",
    "    experiment_name = row[\"name\"]\n",
    "    query_prompt_idx = row[\"query_prompt_idx\"]\n",
    "    context_needed = row[\"context_needed\"]\n",
    "    hyde_context_needed = row[\"hyde_context_needed\"]\n",
    "    suppress_answers = row[\"suppress_answers\"]\n",
    "    \n",
    "    print(f\"sample_ldict: {sample_ldict}\")\n",
    "    print(f\"experiment_name: {experiment_name}\")\n",
    "    print(f\"query_prompt_idx: {query_prompt_idx}\")\n",
    "    print(f\"context_needed: {context_needed}\")\n",
    "    print(f\"hyde_context_needed: {hyde_context_needed}\")\n",
    "    print(f\"suppress_answers: {suppress_answers}\")\n",
    "    \n",
    "    conduct_experiment(sample_ldict, experiment_name, query_prompt_idx,\n",
    "                       context_needed, hyde_context_needed, suppress_answers)\n",
    "\n",
    "print(f\"\\n================== Execution times (in seconds): ==================================\\n\")\n",
    "df_execution_times = pd.DataFrame(execution_times_l, \n",
    "                                  columns=['experiment_name', 'execution_time', 'sample_size', 'bootstrap_n'])\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "df_execution_times.head(100)              \n",
    "\n",
    "print(f\"Total execution time in Minutes: {round(sum(df_execution_times['execution_time']) / 60, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the display format for floats\n",
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time in Minutes: {round(sum(df_execution_times['execution_time']) / 60, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
